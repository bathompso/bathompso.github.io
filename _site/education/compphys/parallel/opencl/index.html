<!DOCTYPE html>
<html><head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    <title>10.3: OpenCL</title>
    <meta name="viewport" content="width=device-width">
    <!-- syntax highlighting CSS -->
    <link rel="stylesheet" href="/styles/css/syntax.css">
    <!-- Necessary JavaScript -->
    <script src='/js/jquery.collapse.js'></script>
    <script type='text/javascript' src='/js/jquery.js?ver=1.10.2'></script>
    <script src="http://ajax.googleapis.com/ajax/libs/jquery/1.8.1/jquery.min.js"></script>
    <!-- RoyalSlider CSS -->
	<link rel='stylesheet' id='new-royalslider-core-css-css'  href='/js/new-royalslider/lib/royalslider/royalslider.css?ver=3.1.7' type='text/css' media='all' />
	<link rel='stylesheet' id='rsMinW-css-css'  href='/js/new-royalslider/lib/royalslider/skins/minimal-white/rs-minimal-white.css?ver=3.1.7' type='text/css' media='all' />
    <!-- Custom CSS -->
    <link rel="stylesheet" href="/styles/css/theme.css">
    <link rel="stylesheet" href="/styles/css/font-awesome.min.css">
    <!-- Custom Google Font -->
    <link rel='stylesheet' id='googlefonts-css'  href='http://fonts.googleapis.com/css?family=PT+Sans:400&subset=latin' type='text/css' media='all' />
    <!-- Google Analytics -->
    <script type="text/javascript">
    	var _gaq = _gaq || [];
        _gaq.push(['_setAccount', 'UA-43423604-1']);
		_gaq.push(['_trackPageview']);
        (function () {
            var ga = document.createElement('script');
            ga.type = 'text/javascript';
            ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(ga, s);
        })();
    </script>
    <!-- App.net Verification -->
    <div style="display: none">
    	<a href="https://alpha.app.net/bathompso" onclick="javascript:_gaq.push(['_trackEvent','outbound-article','http://alpha.app.net']);" class='adn-button' rel='me' data-type='follow' data-width='220' data-height='38' data-user-id='@bathompso'>Follow me on App.net</a>
    </div>
    <script src='https://d2zh9g63fcvyrq.cloudfront.net/adn.js'></script>
    <!-- MathJax -->
    <script type="text/javascript" src="https://c328740.ssl.cf1.rackcdn.com/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <!-- OpenGraph Tags -->
	<meta name="og:title" content="10.3: OpenCL">
	<meta name="og:url" content="http://bathompso.com/education/compphys/parallel/opencl/">
	<meta name="og:type" content="website">
	<meta name="og:locale" content="en_US">
	<meta name="og:site_name" content="bathompso.com">
    <meta property="fb:app_id" content="148947288529876">
	
	
    <script id="facebook-jssdk" src="//connect.facebook.net/en_US/sdk.js#xfbml=1&amp;appId=148947288529876&amp;version=v2.3"></script>
    <!-- Custom JavaScript for site-wide functionality -->
    <script>
      function resizeIframe(obj) {
        obj.style.height = obj.contentWindow.document.body.scrollHeight + 'px';
      }
    </script>
</head>
<body>
	<div class="header">
		<img class="sitelogo" src="/media/fullsize/logo.png" height="100px" />
		<div class="sitetitle"><a href="/">BATHOMPSO.COM</a></div>
		<div class="mainnav">
			
				
					
						<div class="naventry"><a href="/blog/">Blog</a></div>
					
				
			
				
			
				
					
						<div class="naventry"><a href="/education/">Education</a></div>
					
				
			
				
			
				
			
				
			
				
			
				
			
				
					
						<div class="naventry"><a href="/research/">Research</a></div>
					
				
			
				
					
						<div class="naventry"><a href="/resume/">Resum√©</a></div>
					
				
			
				
			
				
			
				
			
				
			
				
			
				
			
				
			
				
			
				
			
		</div>
		<div class="breadcrumbs">
			<a href="/">Home</a> &#187; <a href="/education/">Education</a> &#187; <a href="/education/compphys/">Computational Physics</a> &#187; <a href="/education/compphys/parallel/">Lesson 10: Parallel Computing</a> &#187; 10.3: OpenCL
		</div>
	</div>


	
	<div class="pagecontent">
    	<h1>10.3: OpenCL</h1>

<p>Recently, there has been another revolution in computing power: the use of graphical processing units (GPUs) in general computation. For quite a while, GPUs have been used for heavy computation: rendering and drawing the complex shapes that appear on your monitor. As computer graphics became more sophisticated (animations, transitions, gaming), GPUs became more and more powerful. To handle the enourmous amount of computation involved in rendering a computer game (drawing millions of tiny polygons), GPUs began to add more and more processing units. While each processing unit ran at a small fraction of the speed of a CPU, many advanced GPUs included hundreds (or thousands!) of these units, giving GPUs (generally) more overall processing power than a CPU.</p>

<p>Instead of tasking these GPU units to draw shapes to the screen, we can instead use them for general computation using <a href="http://www.khronos.org/opencl/">OpenCL</a>. OpenCL is a programming framework for massively parallel computing using <strong>any</strong> computation device (CPU or GPU). While other GPU frameworks exist (most notably <a href="http://www.nvidia.com/object/cuda_home_new.html">nVidia&#39;s CUDA</a>), OpenCL is an open standard that supports all types of CPUs and GPUs. Intel, nVidia and AMD are all partners of OpenCL, making the technology compatible with all their products.</p>

<p>In this section we will learn how to harness the massively-parallel architecture of your GPU for use in your Python programs.</p>

<h2>10.3.1 PyOpenCL Installation</h2>

<p>The OpenCL Python module we will use is <a href="http://mathema.tician.de/software/pyopencl/">PyOpenCL</a>. Other options exist, but I have found this module to have great documentation, which is important when learning new techniques. There are several steps involved in installing this module:</p>

<ul>
<li>PyOpenCL requires the boost C++ libraries. You can install them via homebrew: <code>brew install boost</code></li>
<li><a href="https://pypi.python.org/pypi/pyopencl">Download the PyOpenCL source</a> and unpack it.</li>
<li><code>cd</code> into the unpacked directory and build the required binaries: <code>python setup.py build</code></li>
<li>Install the package: <code>sudo python setup.py install</code></li>
</ul>

<p>These steps <em>should</em> complete without any issues. Once everything is installed, re-open your terminal window and start python. Test if the module is installed by typing <code>import pyopencl</code>.</p>

<h2>10.3.2 OpenCL Algorithms</h2>

<p>For the most part, programs leveraging the OpenCL framework are similar to those using PP, as described above. You want to <strong>write your heavy computation into a function that will be called many time via a loop</strong>. However, the code to create this function, and the &quot;job server&quot; that handles it, is much different. Before we delve into the code, let&#39;s go over how OpenCL moves your computations and data around:</p>

<ol>
<li>The function that will handle the parallel computation (called a <em>kernel</em>) is compiled on the computing device. This computing device may be different than your primary CPU.</li>
<li>Your data is imported into your main Python program, and resides in system memory.</li>
<li>Your computing device, if it is not your main CPU, <em>cannot</em> access system memory. Before the kernel can be run, we have to copy the necessary data to the device&#39;s memory.</li>
<li>Your computing device runs the kernel, crunching the numbers and producing results. These results reside in the device memory.</li>
<li>To access the results in your main Python code, we must copy the results from device memory to system memory.</li>
</ol>

<p>Before each run of the kernel we will have to copy over all necessary data, and after each run we will have to copy back the results. For most basic programs you won&#39;t have to think hard about this data transfer. For more advanced programs, however, there are two opposing concepts to consider:</p>

<ul>
<li>Data transfer takes time. While you will still gain massive improvements over a serial code, many copies to and from device memory can add significant overhead.</li>
<li>Most GPUs have limited memory. My MacBook Pro&#39;s graphics memory is only 256MB, miniscule in the face of the 8GB of system memory, and most of that memory is already absorbed by running the display. This means that transfers of large arrays of data may fail due to insufficient memory size.</li>
</ul>

<p>You will have to balance these two issues when deisgning a program. If you need to run a parallel analysis on a large array, do you copy the entire thing over to the GPU at once, or do you break it down into smaller pieces? Sometimes you will have to experiment with how much data your specific device can handle, and modify your algorithms appropriately.</p>

<h2>10.3.3 OpenCL Kernels</h2>

<p>The OpenCL kernel is the main program that runs the parallel computation. As OpenCL is a fairly low-level framework, it is mostly written for the C and FORTRAN programming languages, not Python. As such, the PyOpenCL kernel <strong>must be written in C</strong>. This is a deviation from everything we have learned previously in the course, but only a slight one. As programming languages essentially work the same way, and therefore it will be easy to translate from Python into C.</p>

<p>There are many quirks and differences between writing a Python subroutine and an OpenCL kernel, but the best way to learn is by looking at already-written programs and discussing. Below are two examples of PyOpenCL kernels, and we will walk through the main points of each.</p>

<p><strong>Kernel Example 1: Vector Addition:</strong> The kernel below takes in two vectors and adds them together.</p>

<figure class="highlight"><pre><code class="language-c--" data-lang="c++"><span></span><span class="n">__kernel</span> <span class="kt">void</span> <span class="nf">vadd</span><span class="p">(</span><span class="n">__global</span> <span class="kt">float</span><span class="o">*</span> <span class="n">a</span><span class="p">,</span> <span class="n">__global</span> <span class="kt">float</span><span class="o">*</span> <span class="n">b</span><span class="p">,</span> <span class="n">__global</span> <span class="kt">float</span><span class="o">*</span> <span class="n">c</span><span class="p">,</span> <span class="k">const</span> <span class="kt">unsigned</span> <span class="kt">int</span> <span class="n">count</span><span class="p">)</span>
<span class="p">{</span>
    <span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="n">get_global_id</span><span class="p">(</span><span class="mi">0</span><span class="p">);</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">i</span> <span class="o">&lt;</span> <span class="n">count</span><span class="p">)</span>
        <span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
<span class="p">}</span></code></pre></figure>

<div style='clear:both'></div>

<p>Let&#39;s go over some of the main structure here:</p>

<ol>
<li>Every kernel will start with <code>__kernel void</code>. This is because <strong>kernels do not return any values</strong>. You will notice that vector <code>c</code> is the resulting vector, and it is used as an input into the function. This is true for all OpenCL kernels, and you will have to create an empty vector to save your calculation results to when you write your own OpenCL kernels.</li>
<li>Vector inputs are specified as <code>__global [datatype]*</code>, while scalar inputs are specified as <code>const [datatype]</code>.</li>
<li>Parallel computations are called multiple times via a loop. <code>get_global_id(0)</code> gets the counter from the loop. In OpenCL, it is possible to have a multi-dimensional loop, and each loop index is pulled from the vector <code>get_global_id</code>. So programs with a 3D loop may have <code>get_global_id(0)</code>, <code>get_global_id(1)</code>, and <code>get_global_id(2)</code>.</li>
<li>You may be wondering why we are passing the length of the vectors <code>count</code> to the kernel. This is because <strong>C does not have a built-in way of finding the length of vectors</strong>. If you have a loop over a vector, it is best to either hard-code the vector length into the kernel (if it will always be the same), or pass the length as a variable, as is done here.</li>
</ol>

<p><strong>Kernel Example 2: Matrix Multiplication:</strong> The kernel below takes in two matrices and multiplies them together.</p>

<figure class="highlight"><pre><code class="language-c--" data-lang="c++"><span></span><span class="n">__kernel</span> <span class="kt">void</span> <span class="nf">mmul</span><span class="p">(</span><span class="k">const</span> <span class="kt">int</span> <span class="n">Mdim</span><span class="p">,</span> <span class="k">const</span> <span class="kt">int</span> <span class="n">Ndim</span><span class="p">,</span> <span class="k">const</span> <span class="kt">int</span> <span class="n">Pdim</span><span class="p">,</span> <span class="n">__global</span> <span class="kt">float</span><span class="o">*</span> <span class="n">A</span><span class="p">,</span> <span class="n">__global</span> <span class="kt">float</span><span class="o">*</span> <span class="n">B</span><span class="p">,</span> <span class="n">__global</span> <span class="kt">float</span><span class="o">*</span> <span class="n">C</span><span class="p">)</span>
<span class="p">{</span>
    <span class="kt">int</span> <span class="n">k</span><span class="p">;</span>
    <span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="n">get_global_id</span><span class="p">(</span><span class="mi">0</span><span class="p">);</span>
    <span class="kt">int</span> <span class="n">j</span> <span class="o">=</span> <span class="n">get_global_id</span><span class="p">(</span><span class="mi">1</span><span class="p">);</span>
    <span class="kt">float</span> <span class="n">tmp</span><span class="p">;</span>
    <span class="k">if</span> <span class="p">((</span><span class="n">i</span> <span class="o">&lt;</span> <span class="n">Ndim</span><span class="p">)</span> <span class="o">&amp;&amp;</span> <span class="p">(</span><span class="n">j</span> <span class="o">&lt;</span> <span class="n">Mdim</span><span class="p">))</span>
    <span class="p">{</span>
        <span class="n">tmp</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">;</span>
        <span class="k">for</span> <span class="p">(</span><span class="n">k</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">k</span> <span class="o">&lt;</span> <span class="n">Pdim</span><span class="p">;</span> <span class="n">k</span><span class="o">++</span><span class="p">)</span>
            <span class="n">tmp</span> <span class="o">+=</span> <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="o">*</span><span class="n">Ndim</span><span class="o">+</span><span class="n">k</span><span class="p">]</span> <span class="o">*</span> <span class="n">B</span><span class="p">[</span><span class="n">k</span><span class="o">*</span><span class="n">Pdim</span><span class="o">+</span><span class="n">j</span><span class="p">];</span>
        <span class="n">C</span><span class="p">[</span><span class="n">i</span><span class="o">*</span><span class="n">Ndim</span><span class="o">+</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">tmp</span><span class="p">;</span>
    <span class="p">}</span>
<span class="p">}</span></code></pre></figure>

<div style='clear:both'></div>

<p>We see all of the concepts mentioned in the vector addition case here as well: matrix dimensions are passed as variables into the code, and the counters from this 2D loop are pulled from <code>get_global_id</code>. The only thing new may be the treatment of the matrices themselves. In Python, you would specify a matrix element via <code>A[i,k]</code>, but here there is only one index. This is because <strong>C cannot handle multi-dimensional arrays</strong>. When passing a 2D+ array into an OpenCL kernel, you will have to transform it to a 1D vector, as is done here.</p>

<p>The last thing you may need to know about OpenCL kernels is that advanced (and even basic) math functions may not be available. If you have done any basic C or C++ programming, you know that most often you need to import the <code>math.h</code> or <code>&lt;cmath&gt;</code> headers to get access to most math functions beyond simple addition and multiplication. In OpenCL versions 1.1 and below, this header is not supported, and you lose out on all of these functions. In OpenCL 1.2+, however, <code>math.h</code> is imoported by default, and you can use any of the functions available there.</p>

<h2>10.3.4 PyOpenCL Syntax</h2>

<p>Now that we know how to write our OpenCL kernels, we need to merge them into our Python programs. There are lots of parts to this, so the easiest thing to do is look at an example. Let&#39;s look at the full Python routine for the vector addition example:</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span></span><span class="c1"># Import modules</span>
<span class="kn">import</span> <span class="nn">pyopencl</span> <span class="kn">as</span> <span class="nn">cl</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="c1"># Specify kernel</span>
<span class="n">kernelsource</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">__kernel void vadd(</span>
<span class="s2">    __global float* a,</span>
<span class="s2">    __global float* b,</span>
<span class="s2">    __global float* c,</span>
<span class="s2">    const unsigned int count)</span>
<span class="s2">{</span>
<span class="s2">    int i = get_global_id(0);</span>
<span class="s2">    if (i &lt; count)</span>
<span class="s2">        c[i] = a[i] + b[i];</span>
<span class="s2">}</span>
<span class="s2">&quot;&quot;&quot;</span>

<span class="c1"># Set-Up OpenCL environment</span>
<span class="n">context</span> <span class="o">=</span> <span class="n">cl</span><span class="o">.</span><span class="n">create_some_context</span><span class="p">()</span>    <span class="c1"># Choose Device</span>
<span class="n">queue</span> <span class="o">=</span> <span class="n">cl</span><span class="o">.</span><span class="n">CommandQueue</span><span class="p">(</span><span class="n">context</span><span class="p">)</span>    <span class="c1"># Create Command Queue</span>
<span class="n">program</span> <span class="o">=</span> <span class="n">cl</span><span class="o">.</span><span class="n">Program</span><span class="p">(</span><span class="n">context</span><span class="p">,</span> <span class="n">kernelsource</span><span class="p">)</span><span class="o">.</span><span class="n">build</span><span class="p">()</span>  <span class="c1"># Build Kernel</span>
<span class="n">vadd</span> <span class="o">=</span> <span class="n">program</span><span class="o">.</span><span class="n">vadd</span>                  <span class="c1"># Build Program</span>
<span class="n">vadd</span><span class="o">.</span><span class="n">set_scalar_arg_dtypes</span><span class="p">([</span><span class="bp">None</span><span class="p">,</span> <span class="bp">None</span><span class="p">,</span> <span class="bp">None</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">uint32</span><span class="p">])</span>  <span class="c1"># Set program variable types</span>

<span class="c1"># Create input vectors</span>
<span class="n">h_a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1000</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">h_b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1000</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="c1"># Copy input vectors to device</span>
<span class="n">d_a</span> <span class="o">=</span> <span class="n">cl</span><span class="o">.</span><span class="n">Buffer</span><span class="p">(</span><span class="n">context</span><span class="p">,</span> <span class="n">cl</span><span class="o">.</span><span class="n">mem_flags</span><span class="o">.</span><span class="n">READ_ONLY</span> <span class="o">|</span> <span class="n">cl</span><span class="o">.</span><span class="n">mem_flags</span><span class="o">.</span><span class="n">COPY_HOST_PTR</span><span class="p">,</span> <span class="n">hostbuf</span><span class="o">=</span><span class="n">h_a</span><span class="p">)</span>
<span class="n">d_b</span> <span class="o">=</span> <span class="n">cl</span><span class="o">.</span><span class="n">Buffer</span><span class="p">(</span><span class="n">context</span><span class="p">,</span> <span class="n">cl</span><span class="o">.</span><span class="n">mem_flags</span><span class="o">.</span><span class="n">READ_ONLY</span> <span class="o">|</span> <span class="n">cl</span><span class="o">.</span><span class="n">mem_flags</span><span class="o">.</span><span class="n">COPY_HOST_PTR</span><span class="p">,</span> <span class="n">hostbuf</span><span class="o">=</span><span class="n">h_b</span><span class="p">)</span>

<span class="c1"># Create output vector</span>
<span class="n">h_c</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1000</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="c1"># Copy output vector to device</span>
<span class="n">d_c</span> <span class="o">=</span> <span class="n">cl</span><span class="o">.</span><span class="n">Buffer</span><span class="p">(</span><span class="n">context</span><span class="p">,</span> <span class="n">cl</span><span class="o">.</span><span class="n">mem_flags</span><span class="o">.</span><span class="n">WRITE_ONLY</span><span class="p">,</span> <span class="n">h_c</span><span class="o">.</span><span class="n">nbytes</span><span class="p">)</span>

<span class="c1"># Execute kernel</span>
<span class="n">vadd</span><span class="p">(</span><span class="n">queue</span><span class="p">,</span> <span class="n">h_a</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="bp">None</span><span class="p">,</span> <span class="n">d_a</span><span class="p">,</span> <span class="n">d_b</span><span class="p">,</span> <span class="n">d_c</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>

<span class="c1"># Read back results from the compute device</span>
<span class="n">cl</span><span class="o">.</span><span class="n">enqueue_copy</span><span class="p">(</span><span class="n">queue</span><span class="p">,</span> <span class="n">h_c</span><span class="p">,</span> <span class="n">d_c</span><span class="p">)</span></code></pre></figure>

<div style='clear:both'></div>

<p>The list below will walk through each of the commented lines and explain what is happening in that region of the code.</p>

<h3>Setting up the OpenCL environment:</h3>

<ul>
<li><strong>Import modules</strong>: At minimum you must import PyOpenCL and NumPy into your program.</li>
<li><strong>Specify kernel</strong>: This is the same kernel that we saw in the example before, but enclosed in triple quotations (&quot;&quot;&quot;) and saved as a string variable. This string will be passed to PyOpenCL later in the code and built on the computing device.</li>
<li><strong>Choose device</strong>: The <code>create_some_context()</code> command will set up a computing environment on the specified computing device. If a machine has more than one possible options (a CPU and GPU), the user will be asked which device they wish to use.</li>
<li><strong>Create command queue</strong>: Similar to PP, PyOpenCL creates a command queue which passes loop iterations to idle cores on the computing device.</li>
<li><strong>Build kernel</strong>: The <code>cl.Program</code> command takes the computing environment and compiles the kernel on it.</li>
<li><strong>Build program</strong>: The kernel string may specify more than one program (you may have subroutines for the kernel. This line specifies which function within the kernel string should be fed the input values.</li>
<li><strong>Set program variable types</strong>: While you have specified the expected data types in the kernel, PyOpenCL must know how to format the input data so that everything matches up between devices. Vector inputs have a variable type of <code>None</code>, while scalar data types are specified using the NumPy variable classifications. (In this example, we are passing an unsigned 32-bit integer).</li>
</ul>

<h3>Creating and copying data:</h3>

<ul>
<li><strong>Create input vectors</strong>: This is mostly stuff you have seen before. We create a vector of random numbers (although we could import the data from anywhere) to be input into the program. The only difference is the <code>.astype(np.float32)</code>. This is because OpenCL (at least earlier versions of it) cannot handle the standard 64-bit floating point numbers that NumPy uses by default. If we passed a 64-bit float array to the OpenCL kernel, the memory locations would not line up, and we would get garbage results. Make sure to convert any arrays you are passing to OpenCL to 32-bit variables (float, int, uint, or otherwise).</li>
<li><strong>Copy input vectors to device</strong>: As stated in 10.3.2, the computing device cannot access system memory, and variables must be copied to the computing device before running the kernel. The variable <code>hostbuf</code> is the input vector that was generated in Python, and the output is the new device array. You will notice two memory flags are set for input vectors: <code>READ_ONLY</code> and <code>COPY_HOST_PTR</code>. <code>READ_ONLY</code> means that the vector is an input value and should not be changed. <code>COPY_HOST_PTR</code> means that we want to copy out the memory reference position of the vector to the computing device. Both of these memory flags should be set for any vector being copied to the computing device</li>
<li><strong>Create output vector</strong>: We need to make a placeholder for the output vector we expect. Here we simply specify a <code>np.zeros</code> of the same length as the inputs, making sure to convert it to a <code>np.float32</code> type as well.</li>
<li><strong>Copy output vector to device</strong>: You will notice that the memory flags for this command are <code>WRITE_ONLY</code>, which makes sense considering we want to be able to modify this array when printing results. The <code>cl.Buffer</code> call is slightly different in the fact that we pass it the number of bytes that <code>h_c</code> takes up, as opposed to passing the pointer (like we did for the inputs). This is because we are simply <em>creating the space for the results in the computing device&#39;s memory</em>, not really copying anything there.</li>
</ul>

<h3>Executing the kernel and returning results:</h3>

<ul>
<li><strong>Execute kernel</strong>: Now that everything is copied to the computing device, we can run the kernel on all the data. The <code>vadd()</code> command takes several arguments:

<ul>
<li>The first argument of the <code>vadd()</code> command is the command queue.</li>
<li>The second is the &quot;shape&quot; of the loop that should be run. Remmber, we get the increment of the loop within the kernel via the <code>get_global_id</code> function; the second argument specifies that array. In the example, we are passing the &quot;shape&quot; of our 1D input vector, meaning that we will have a 1D loop of length 1000.</li>
<li>The third argument is the data type of the kernel&#39;s return values. As kernels will not return data, this is always <code>None</code>.</li>
<li>The last arguments are the input values into the <code>vadd</code> kernel. Remember, we need to pass the <em>copied</em> vector inputs and outputs to the program for it to work properly. Scalar values do not have to be copied, and can be specified using their current names in the Python program.</li>
</ul></li>
<li><strong>Copying results</strong>: Once the kernel is complete, the results vector still resides on the computing device. To copy it back, we use the <code>cl.enqueue_copy</code> command to move the device&#39;s results (<code>d_c</code>) back to the Python program&#39;s vector (<code>h_c</code>).</li>
</ul>

<p>After copying back the results from the kernel, your Python program can continue as normal. To help you get a further grip on writing OpenCL programs, let us also look over the matrix multiplication example we saw in 10.3.3:</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span></span><span class="c1"># Import modules</span>
<span class="kn">import</span> <span class="nn">pyopencl</span> <span class="kn">as</span> <span class="nn">cl</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="c1"># Specify kernel</span>
<span class="n">kernelsource</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">__kernel void mmul(</span>
<span class="s2">   const int Mdim,</span>
<span class="s2">   const int Ndim,</span>
<span class="s2">   const int Pdim,</span>
<span class="s2">   __global float* A,</span>
<span class="s2">   __global float* B,</span>
<span class="s2">   __global float* C)</span>
<span class="s2">{</span>
<span class="s2">   int k;</span>
<span class="s2">   int i = get_global_id(0);</span>
<span class="s2">   int j = get_global_id(1);</span>
<span class="s2">   float tmp;</span>
<span class="s2">   if ((i &lt; Ndim) &amp;&amp; (j &lt; Mdim))</span>
<span class="s2">   {</span>
<span class="s2">       tmp = 0.0;</span>
<span class="s2">       for (k = 0; k &lt; Pdim; k++)</span>
<span class="s2">           tmp += A[i*Ndim+k] * B[k*Pdim+j];</span>
<span class="s2">       C[i*Ndim+j] = tmp;</span>
<span class="s2">   }</span>
<span class="s2">}</span>
<span class="s2">&quot;&quot;&quot;</span>

<span class="c1"># Set-Up OpenCL environment</span>
<span class="n">context</span> <span class="o">=</span> <span class="n">cl</span><span class="o">.</span><span class="n">create_some_context</span><span class="p">()</span>    <span class="c1"># Choose Device</span>
<span class="n">queue</span> <span class="o">=</span> <span class="n">cl</span><span class="o">.</span><span class="n">CommandQueue</span><span class="p">(</span><span class="n">context</span><span class="p">)</span>    <span class="c1"># Create Command Queue</span>
<span class="n">program</span> <span class="o">=</span> <span class="n">cl</span><span class="o">.</span><span class="n">Program</span><span class="p">(</span><span class="n">context</span><span class="p">,</span> <span class="n">kernelsource</span><span class="p">)</span><span class="o">.</span><span class="n">build</span><span class="p">()</span>  <span class="c1"># Build Kernel</span>
<span class="n">mmul</span> <span class="o">=</span> <span class="n">program</span><span class="o">.</span><span class="n">mmul</span>                  <span class="c1"># Build Program</span>
<span class="n">mmul</span><span class="o">.</span><span class="n">set_scalar_arg_dtypes</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">uint32</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">uint32</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">uint32</span><span class="p">,</span> <span class="bp">None</span><span class="p">,</span> <span class="bp">None</span><span class="p">,</span> <span class="bp">None</span><span class="p">])</span>  <span class="c1"># Set program variable types</span>

<span class="c1"># Set up matrix sizes</span>
<span class="n">Ndim</span><span class="p">,</span> <span class="n">Pdim</span><span class="p">,</span> <span class="n">Mdim</span> <span class="o">=</span> <span class="mi">500</span><span class="p">,</span> <span class="mi">600</span><span class="p">,</span> <span class="mi">700</span>
<span class="n">sizeA</span> <span class="o">=</span> <span class="n">Ndim</span> <span class="o">*</span> <span class="n">Pdim</span>
<span class="n">sizeB</span> <span class="o">=</span> <span class="n">Pdim</span> <span class="o">*</span> <span class="n">Mdim</span>
<span class="n">sizeC</span> <span class="o">=</span> <span class="n">Ndim</span> <span class="o">*</span> <span class="n">Mdim</span>

<span class="c1"># Create input matrices</span>
<span class="n">h_a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">sizeA</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">h_b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">sizeB</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="c1"># Copy input matrices to device</span>
<span class="n">d_a</span> <span class="o">=</span> <span class="n">cl</span><span class="o">.</span><span class="n">Buffer</span><span class="p">(</span><span class="n">context</span><span class="p">,</span> <span class="n">cl</span><span class="o">.</span><span class="n">mem_flags</span><span class="o">.</span><span class="n">READ_ONLY</span> <span class="o">|</span> <span class="n">cl</span><span class="o">.</span><span class="n">mem_flags</span><span class="o">.</span><span class="n">COPY_HOST_PTR</span><span class="p">,</span> <span class="n">hostbuf</span><span class="o">=</span><span class="n">h_a</span><span class="p">)</span>
<span class="n">d_b</span> <span class="o">=</span> <span class="n">cl</span><span class="o">.</span><span class="n">Buffer</span><span class="p">(</span><span class="n">context</span><span class="p">,</span> <span class="n">cl</span><span class="o">.</span><span class="n">mem_flags</span><span class="o">.</span><span class="n">READ_ONLY</span> <span class="o">|</span> <span class="n">cl</span><span class="o">.</span><span class="n">mem_flags</span><span class="o">.</span><span class="n">COPY_HOST_PTR</span><span class="p">,</span> <span class="n">hostbuf</span><span class="o">=</span><span class="n">h_b</span><span class="p">)</span>

<span class="c1"># Create output matrix</span>
<span class="n">h_c</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">sizeC</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="c1"># Copy output matrix to device</span>
<span class="n">d_c</span> <span class="o">=</span> <span class="n">cl</span><span class="o">.</span><span class="n">Buffer</span><span class="p">(</span><span class="n">context</span><span class="p">,</span> <span class="n">cl</span><span class="o">.</span><span class="n">mem_flags</span><span class="o">.</span><span class="n">WRITE_ONLY</span><span class="p">,</span> <span class="n">h_c</span><span class="o">.</span><span class="n">nbytes</span><span class="p">)</span>

<span class="c1"># Execute kernel</span>
<span class="n">loopshape</span> <span class="o">=</span> <span class="p">(</span><span class="n">Ndim</span><span class="p">,</span> <span class="n">Mdim</span><span class="p">)</span>
<span class="n">mmul</span><span class="p">(</span><span class="n">queue</span><span class="p">,</span> <span class="n">loopshape</span><span class="p">,</span> <span class="bp">None</span><span class="p">,</span> <span class="n">Mdim</span><span class="p">,</span> <span class="n">Ndim</span><span class="p">,</span> <span class="n">Pdim</span><span class="p">,</span> <span class="n">d_a</span><span class="p">,</span> <span class="n">d_b</span><span class="p">,</span> <span class="n">d_c</span><span class="p">)</span>

<span class="c1"># Read back results from the compute device</span>
<span class="n">cl</span><span class="o">.</span><span class="n">enqueue_copy</span><span class="p">(</span><span class="n">queue</span><span class="p">,</span> <span class="n">h_c</span><span class="p">,</span> <span class="n">d_c</span><span class="p">)</span></code></pre></figure>

<div style='clear:both'></div>

<p>Almost everything here is the same as in the vector addition example, with the only difference being the <code>loopshape</code> variable. In this example we have a 2D loop (over every element in array <code>h_c</code>), with the &quot;shape&quot; defined by <code>loopshape</code>. In general you can make the shape of the loop any dimension by specifying more elements in the <code>loopshape</code> list. You will also notice that our &quot;matrices&quot; are actually arrays with the same number of elements. Matrix <code>h_a</code> should have a size of \( 500 \times 600 \), but instead is a 300,000 element vector. This is due to the fact that OpenCL can only handle 1D vectors instead of 2D matrices.</p>

<p>These two examples cover much of what you need to know about how to write OpenCL programs. The clever part is figuring out which parts of the code can be parallelized, and how you can manipulate your algorithms to fit within the confines of the OpenCL limitations (no <code>math.h</code> header, no matrices, etc.).</p>


	</div>
	
	
<div style="clear: both; padding-top: 15px;">&nbsp;</div>
<div class="footercontainer">
	<div class="footercontent">
		<img src="/generated/bioface-200x200-353493.png" class="footerbiopic" >
		<div class="footertext">
			<h2>Ben Thompson</h2>
			<p>Master of all things bathompso. Lifelong astrophysicist enjoying a new experience in data science. Technology enthusiast and evangelist of all things Apple.</p>
			<div class="footerlink" style="margin-left: 90px;"><a href="/resume/">Resum√©</a></div>
			<div class="footerlink"><a href="/research/">Research</a></div>
			<div class="footerlink" style="border: 0"><a href="https://github.com/bathompso/">Code</a></div>
		</div>
		<div class="attributions">bathompso.com is powered by <a href="http://jekyllrb.com">Jekyll</a>, hosted by AWS</div>
	</div>
</div>

</body>
</html>

