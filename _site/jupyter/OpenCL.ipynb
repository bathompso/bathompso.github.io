{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenCL\n",
    "Recently, there has been another revolution in computing power: the use of graphical processing units (GPUs) in general computation. For quite a while, GPUs have been used for heavy computation: rendering and drawing the complex shapes that appear on your monitor. As computer graphics became more sophisticated (animations, transitions, gaming), GPUs became more and more powerful. To handle the enourmous amount of computation involved in rendering a computer game (drawing millions of tiny polygons), GPUs began to add more and more processing units. While each processing unit ran at a small fraction of the speed of a CPU, many advanced GPUs included hundreds (or thousands!) of these units, giving GPUs (generally) more overall processing power than a CPU.\n",
    "\n",
    "Instead of tasking these GPU units to draw shapes to the screen, we can instead use them for general computation using [OpenCL](http://www.khronos.org/opencl/). OpenCL is a programming framework for massively parallel computing using **any** computation device (CPU or GPU). While other GPU frameworks exist (most notably [nVidia's CUDA](http://www.nvidia.com/object/cuda_home_new.html)), OpenCL is an open standard that supports all types of CPUs and GPUs. Intel, nVidia and AMD are all partners of OpenCL, making the technology compatible with all their products.\n",
    "\n",
    "In this post we will learn how to harness the massively-parallel architecture of your GPU for use in your Python programs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyOpenCL Installation\n",
    "\n",
    "The OpenCL Python module we will use is [PyOpenCL](http://mathema.tician.de/software/pyopencl/). Other options exist, but I have found this module to have great documentation, which is important when learning new techniques. There are several steps involved in installing this module:\n",
    "\n",
    "* PyOpenCL requires the boost C++ libraries. You can install them via homebrew: ``brew install boost``\n",
    "* Install the Python module: ``pip install pyopencl``\n",
    "\n",
    "These steps *should* complete without any issues. Once everything is installed, re-open your terminal window and start python. Test if the module is installed by typing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pyopencl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenCL Algorithms\n",
    "\n",
    "For the most part, programs leveraging the OpenCL framework are similar to those using python-native functions: You want to **write your heavy computation into a function that will be called many times via a loop**. However, the code to create this function, and the \"job server\" that handles it, is much different. Before we delve into the code, let's go over how OpenCL moves your computations and data around:\n",
    "\n",
    "1. The function that will handle the parallel computation (called a *kernel*) is compiled on the computing device. This computing device may be different than your primary CPU.\n",
    "2. Your data is imported into your main Python program, and resides in system memory.\n",
    "3. Your computing device, if it is not your main CPU, *cannot* access system memory. Before the kernel can be run, we have to copy the necessary data to the device's memory.\n",
    "4. Your computing device runs the kernel, crunching the numbers and producing results. These results reside in the device memory.\n",
    "5. To access the results in your main Python code, we must copy the results from device memory to system memory.\n",
    "\n",
    "Before each run of the kernel we will have to copy over all necessary data, and after each run we will have to copy back the results. For most basic programs you won't have to think hard about this data transfer. For more advanced programs, however, there are two opposing concepts to consider:\n",
    "\n",
    "* Data transfer takes time. While you will still gain massive improvements over a serial code, many copies to and from device memory can add significant overhead.\n",
    "* Most GPUs have limited memory. My MacBook Pro's graphics memory is only 256MB, miniscule in the face of the 8GB of system memory, and most of that memory is already absorbed by running the display. This means that transfers of large arrays of data may fail due to insufficient memory size.\n",
    "\n",
    "You will have to balance these two issues when deisgning a program. If you need to run a parallel analysis on a large array, do you copy the entire thing over to the GPU at once, or do you break it down into smaller pieces? Sometimes you will have to experiment with how much data your specific device can handle, and modify your algorithms appropriately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenCL Kernels\n",
    "\n",
    "The OpenCL kernel is the main program that runs the parallel computation. As OpenCL is a fairly low-level framework, it is mostly written for the C and FORTRAN programming languages, not Python. As such, the PyOpenCL kernel **must be written in C**. This is a deviation from everything we have learned previously in the course, but only a slight one. As programming languages essentially work the same way, and therefore it will be easy to translate from Python into C.\n",
    "\n",
    "There are many quirks and differences between writing a Python subroutine and an OpenCL kernel, but the best way to learn is by looking at already-written programs and discussing. Below are two examples of PyOpenCL kernels, and we will walk through the main points of each.\n",
    "\n",
    "**Kernel Example 1: Vector Addition:** The kernel below takes in two vectors and adds them together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_ = '''\n",
    "__kernel void vadd(__global float* a, __global float* b, __global float* c, const unsigned int count)\n",
    "{\n",
    "    int i = get_global_id(0);\n",
    "    if (i < count)\n",
    "        c[i] = a[i] + b[i];\n",
    "}\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go over some of the main structure here:\n",
    "\n",
    "1. Every kernel will start with ``__kernel void``. This is because **kernels do not return any values**. You will notice that vector ``c`` is the resulting vector, and it is used as an input into the function. This is true for all OpenCL kernels, and you will have to create an empty vector to save your calculation results to when you write your own OpenCL kernels.\n",
    "2. Vector inputs are specified as ``__global [datatype]*``, while scalar inputs are specified as ``const [datatype]``.\n",
    "3. Parallel computations are called multiple times via a loop. ``get_global_id(0)`` gets the counter from the loop. In OpenCL, it is possible to have a multi-dimensional loop, and each loop index is pulled from the vector ``get_global_id``. So programs with a 3D loop may have ``get_global_id(0)``, ``get_global_id(1)``, and ``get_global_id(2)``.\n",
    "4. You may be wondering why we are passing the length of the vectors ``count`` to the kernel. This is because **C does not have a built-in way of finding the length of vectors**. If you have a loop over a vector, it is best to either hard-code the vector length into the kernel (if it will always be the same), or pass the length as a variable, as is done here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Kernel Example 2: Matrix Multiplication:** The kernel below takes in two matrices and multiplies them together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_ = '''\n",
    "__kernel void mmul(const int Mdim, const int Ndim, const int Pdim, __global float* A, __global float* B, __global float* C)\n",
    "{\n",
    "\tint k;\n",
    "\tint i = get_global_id(0);\n",
    "\tint j = get_global_id(1);\n",
    "\tfloat tmp;\n",
    "\tif ((i < Ndim) && (j < Mdim))\n",
    "\t{\n",
    "\t\ttmp = 0.0;\n",
    "\t\tfor (k = 0; k < Pdim; k++)\n",
    "\t\t\ttmp += A[i*Ndim+k] * B[k*Pdim+j];\n",
    "\t\tC[i*Ndim+j] = tmp;\n",
    "\t}\n",
    "}\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see all of the concepts mentioned in the vector addition case here as well: matrix dimensions are passed as variables into the code, and the counters from this 2D loop are pulled from ``get_global_id``. The only thing new may be the treatment of the matrices themselves. In Python, you would specify a matrix element via ``A[i,k]``, but here there is only one index. This is because **C cannot handle multi-dimensional arrays**. When passing a 2D+ array into an OpenCL kernel, you will have to transform it to a 1D vector, as is done here.\n",
    "\n",
    "The last thing you may need to know about OpenCL kernels is that advanced (and even basic) math functions may not be available. If you have done any basic C or C++ programming, you know that most often you need to import the ``math.h`` or ``<cmath>`` headers to get access to most math functions beyond simple addition and multiplication. In OpenCL versions 1.1 and below, this header is not supported, and you lose out on all of these functions. In OpenCL 1.2+, however, ``math.h`` is imoported by default, and you can use any of the functions available there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyOpenCL Syntax\n",
    "\n",
    "Now that we know how to write our OpenCL kernels, we need to merge them into our Python programs. There are lots of parts to this, so the easiest thing to do is look at an example. Let's look at the full Python routine for the vector addition example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.95341969,  1.0749675 ,  1.02363062,  0.83763766,  0.77136636,\n",
       "        1.11196077,  0.75834322,  1.08344018,  0.86464638,  0.71710968,\n",
       "        1.74478376,  0.56969404,  0.4927811 ,  1.11953461,  1.21910572,\n",
       "        0.77456665,  1.04502797,  1.49689388,  0.83661848,  1.26157629,\n",
       "        0.84894246,  1.23585081,  1.3727479 ,  1.13614559,  1.53942013,\n",
       "        0.25364208,  0.59682941,  1.27365041,  0.76266575,  0.50780398,\n",
       "        0.84237862,  1.40266323,  1.31092596,  0.961272  ,  1.51455188,\n",
       "        0.60342509,  1.78912687,  0.7039203 ,  0.66691148,  0.83449465,\n",
       "        0.73041582,  1.78259635,  1.11679316,  1.04288459,  0.73431671,\n",
       "        0.76272905,  0.97013021,  0.10226849,  1.21516252,  0.5592804 ,\n",
       "        0.79124743,  0.64513403,  0.69029027,  0.93785429,  0.93938446,\n",
       "        1.61494005,  0.93005008,  0.8206327 ,  1.60221291,  0.43116963,\n",
       "        1.35946679,  0.58356392,  0.73393077,  1.18942904,  1.55843925,\n",
       "        1.85044611,  1.29299426,  0.86520618,  0.58911562,  1.26407397,\n",
       "        0.32507896,  1.38022602,  1.23042512,  0.60713929,  1.45712733,\n",
       "        1.39692807,  0.49772519,  0.77323395,  1.11013806,  0.84603548,\n",
       "        1.53819382,  1.32722378,  0.77110016,  1.42555094,  0.19436646,\n",
       "        1.21778131,  1.25270534,  0.756791  ,  1.6125977 ,  0.48178729,\n",
       "        1.00499582,  0.83418524,  0.67859101,  1.43434441,  1.41875672,\n",
       "        0.59970903,  0.66013306,  1.08919203,  0.54965574,  1.58578825], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import modules\n",
    "import pyopencl as cl\n",
    "import numpy as np\n",
    "\n",
    "# Specify kernel\n",
    "kernelsource = \"\"\"\n",
    "__kernel void vadd(\n",
    "    __global float* a,\n",
    "    __global float* b,\n",
    "    __global float* c,\n",
    "    const unsigned int count)\n",
    "{\n",
    "    int i = get_global_id(0);\n",
    "    if (i < count)\n",
    "        c[i] = a[i] + b[i];\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# Set-Up OpenCL environment\n",
    "context = cl.create_some_context()                   # Choose Device\n",
    "queue = cl.CommandQueue(context)                     # Create Command Queue\n",
    "program = cl.Program(context, kernelsource).build()  # Build Kernel\n",
    "vadd = program.vadd                                  # Build Program\n",
    "vadd.set_scalar_arg_dtypes([None, None, None, np.uint32])  # Set program variable types\n",
    "\n",
    "# Create input vectors\n",
    "h_a = np.random.rand(100).astype(np.float32)\n",
    "h_b = np.random.rand(100).astype(np.float32)\n",
    "# Copy input vectors to device\n",
    "d_a = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=h_a)\n",
    "d_b = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=h_b)\n",
    "\n",
    "# Create output vector\n",
    "h_c = np.zeros(100).astype(np.float32)\n",
    "# Copy output vector to device\n",
    "d_c = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_c.nbytes)\n",
    "\n",
    "# Execute kernel\n",
    "vadd(queue, h_a.shape, None, d_a, d_b, d_c, 100)\n",
    "\n",
    "# Read back results from the compute device\n",
    "cl.enqueue_copy(queue, h_c, d_c)\n",
    "\n",
    "h_c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's walk through each of the comments in the above code.\n",
    "\n",
    "#### Setting up the OpenCL environment:\n",
    "\n",
    "* **Import modules**: At minimum you must import PyOpenCL and NumPy into your program.\n",
    "* **Specify kernel**: This is the same kernel that we saw in the example before, but enclosed in triple quotations (\"\"\") and saved as a string variable. This string will be passed to PyOpenCL later in the code and built on the computing device.\n",
    "* **Choose device**: The ``create_some_context()`` command will set up a computing environment on the specified computing device. If a machine has more than one possible options (a CPU and GPU), the user will be asked which device they wish to use.\n",
    "* **Create command queue**: Similar to PP, PyOpenCL creates a command queue which passes loop iterations to idle cores on the computing device.\n",
    "* **Build kernel**: The ``cl.Program`` command takes the computing environment and compiles the kernel on it.\n",
    "* **Build program**: The kernel string may specify more than one program (you may have subroutines for the kernel. This line specifies which function within the kernel string should be fed the input values.\n",
    "* **Set program variable types**: While you have specified the expected data types in the kernel, PyOpenCL must know how to format the input data so that everything matches up between devices. Vector inputs have a variable type of ``None``, while scalar data types are specified using the NumPy variable classifications. (In this example, we are passing an unsigned 32-bit integer).\n",
    "\n",
    "#### Creating and copying data:\n",
    "\n",
    "* **Create input vectors**: This is mostly stuff you have seen before. We create a vector of random numbers (although we could import the data from anywhere) to be input into the program. The only difference is the ``.astype(np.float32)``. This is because OpenCL (at least earlier versions of it) cannot handle the standard 64-bit floating point numbers that NumPy uses by default. If we passed a 64-bit float array to the OpenCL kernel, the memory locations would not line up, and we would get garbage results. Make sure to convert any arrays you are passing to OpenCL to 32-bit variables (float, int, uint, or otherwise).\n",
    "* **Copy input vectors to device**: As stated in 10.3.2, the computing device cannot access system memory, and variables must be copied to the computing device before running the kernel. The variable ``hostbuf`` is the input vector that was generated in Python, and the output is the new device array. You will notice two memory flags are set for input vectors: ``READ_ONLY`` and ``COPY_HOST_PTR``. ``READ_ONLY`` means that the vector is an input value and should not be changed. ``COPY_HOST_PTR`` means that we want to copy out the memory reference position of the vector to the computing device. Both of these memory flags should be set for any vector being copied to the computing device\n",
    "* **Create output vector**: We need to make a placeholder for the output vector we expect. Here we simply specify a ``np.zeros`` of the same length as the inputs, making sure to convert it to a ``np.float32`` type as well.\n",
    "* **Copy output vector to device**: You will notice that the memory flags for this command are ``WRITE_ONLY``, which makes sense considering we want to be able to modify this array when printing results. The ``cl.Buffer`` call is slightly different in the fact that we pass it the number of bytes that ``h_c`` takes up, as opposed to passing the pointer (like we did for the inputs). This is because we are simply *creating the space for the results in the computing device's memory*, not really copying anything there.\n",
    "\n",
    "#### Executing the kernel and returning results:\n",
    "\n",
    "* **Execute kernel**: Now that everything is copied to the computing device, we can run the kernel on all the data. The ``vadd()`` command takes several arguments:\n",
    " * The first argument of the ``vadd()`` command is the command queue.\n",
    " * The second is the \"shape\" of the loop that should be run. Remmber, we get the increment of the loop within the kernel via the ``get_global_id`` function; the second argument specifies that array. In the example, we are passing the \"shape\" of our 1D input vector, meaning that we will have a 1D loop of length 1000.\n",
    " * The third argument is the data type of the kernel's return values. As kernels will not return data, this is always ``None``.\n",
    " * The last arguments are the input values into the ``vadd`` kernel. Remember, we need to pass the *copied* vector inputs and outputs to the program for it to work properly. Scalar values do not have to be copied, and can be specified using their current names in the Python program.\n",
    "* **Copying results**: Once the kernel is complete, the results vector still resides on the computing device. To copy it back, we use the ``cl.enqueue_copy`` command to move the device's results (``d_c``) back to the Python program's vector (``h_c``).\n",
    "\n",
    "After copying back the results from the kernel, your Python program can continue as normal (or print them out, as done aboe).\n",
    "\n",
    "To help get a further grip on writing OpenCL programs, let's also look over the matrix multiplication example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 150.93429565,  151.26486206,  152.15020752, ...,  147.43330383,\n",
       "         149.49533081,  152.80351257],\n",
       "       [ 153.1399231 ,  151.36068726,  155.5138855 , ...,  146.41668701,\n",
       "         152.52696228,  156.67251587],\n",
       "       [ 148.86749268,  150.17826843,  147.72998047, ...,  142.72929382,\n",
       "         149.19018555,  155.52618408],\n",
       "       ..., \n",
       "       [ 163.92628479,  160.3528595 ,  163.3830719 , ...,  158.5124054 ,\n",
       "         160.72270203,  164.8132019 ],\n",
       "       [ 149.52366638,  147.22966003,  150.66053772, ...,  144.29576111,\n",
       "         150.28434753,  154.43119812],\n",
       "       [ 159.17720032,  153.43807983,  157.72988892, ...,  149.6648407 ,\n",
       "         156.59985352,  160.33921814]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyopencl as cl\n",
    "import numpy as np\n",
    "\n",
    "# Specify kernel\n",
    "kernelsource = \"\"\"\n",
    "__kernel void mmul(\n",
    "    const int Mdim,\n",
    "    const int Ndim,\n",
    "    const int Pdim,\n",
    "    __global float* A,\n",
    "    __global float* B,\n",
    "    __global float* C)\n",
    "{\n",
    "    int k;\n",
    "    int i = get_global_id(0);\n",
    "    int j = get_global_id(1);\n",
    "    float tmp;\n",
    "    if ((i < Ndim) && (j < Mdim)) {\n",
    "        tmp = 0.0;\n",
    "        for (k = 0; k < Pdim; k++)\n",
    "            tmp += A[i*Ndim+k] * B[k*Mdim+j];\n",
    "        C[i*Mdim+j] = tmp;\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# Set-Up OpenCL environment\n",
    "context = cl.create_some_context()                   # Choose Device\n",
    "queue = cl.CommandQueue(context)                     # Create Command Queue\n",
    "program = cl.Program(context, kernelsource).build()  # Build Kernel\n",
    "mmul = program.mmul                                  # Build Program\n",
    "mmul.set_scalar_arg_dtypes([np.uint32, np.uint32, np.uint32, None, None, None])  # Set program variable types\n",
    "\n",
    "# Set up matrix sizes\n",
    "Ndim, Pdim, Mdim = 500, 600, 700\n",
    "sizeA = Ndim * Pdim\n",
    "sizeB = Pdim * Mdim\n",
    "sizeC = Ndim * Mdim\n",
    "\n",
    "# Create input matrices\n",
    "h_a = np.random.rand(sizeA).astype(np.float32)\n",
    "h_b = np.random.rand(sizeB).astype(np.float32)\n",
    "# Copy input matrices to device\n",
    "d_a = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=h_a)\n",
    "d_b = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=h_b)\n",
    "\n",
    "# Create output matrix\n",
    "h_c = np.zeros(sizeC).astype(np.float32)\n",
    "# Copy output matrix to device\n",
    "d_c = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, h_c.nbytes)\n",
    "\n",
    "# Execute kernel\n",
    "loopshape = (Ndim, Mdim)\n",
    "mmul(queue, loopshape, None, Mdim, Ndim, Pdim, d_a, d_b, d_c)\n",
    "\n",
    "# Read back results from the compute device\n",
    "cl.enqueue_copy(queue, h_c, d_c)\n",
    "\n",
    "np.reshape(h_c, (Ndim, Mdim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the matrices had to be coerced into a 1-dimensions format, as C does not understand matrices. The ``np.ravel`` and ``np.reshape`` functions will be your friend here.\n",
    "\n",
    "These two examples cover much of what you need to know about how to write OpenCL programs. The clever part is figuring out which parts of the code can be parallelized, and how you can manipulate your algorithms to fit within the confines of the OpenCL limitations (no ``math.h`` header, no matrices, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  },
  "toc": {
   "toc_cell": false,
   "toc_number_sections": true,
   "toc_threshold": "2",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
