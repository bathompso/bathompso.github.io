<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>bathompso.com</title>
    <description></description>
    <link>http://localhost:4000/</link>
    <atom:link href="http://localhost:4000/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Tue, 25 Apr 2017 01:24:59 -0700</pubDate>
    <lastBuildDate>Tue, 25 Apr 2017 01:24:59 -0700</lastBuildDate>
    <generator>Jekyll v3.4.3</generator>
    
      <item>
        <title>Hidden Tips For Transitioning From Academia To Data Science</title>
        <description>&lt;p&gt;I&amp;#39;m hardly alone in my path from academia into the world of data science, which means there exist a multitude of guides and &lt;a href=&quot;http://tommyblanchard.com/how-to-make-the-transition-from-academia-to-data-science&quot;&gt;blog posts&lt;/a&gt; explaining the steps you need to take to also make the transition. Most focus on how to transition skills gained via a Ph.D. into those &amp;quot;necessary&amp;quot; for work in data science, or how to improve your coding. These are definitely useful comments (and I&amp;#39;ll list out some more conventional ones as well), but there are some questions that I almost never see in these guides that I think are absolutely necessary to answer before attempting any transition.&lt;/p&gt;

&lt;p&gt;First, I&amp;#39;ll get my list of &amp;quot;known&amp;quot; transition tips out of the way:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Learn a coding language.&lt;/strong&gt; This one is obvious, and most Ph.D. students are hopefully familiar with a language like Python or R via their research. If not, there are many good textbooks and MOOCs to teach you how to code. Spend a few weeks to get to a basic level of proficiency, and then continue to improve your skills by writing programs to help with your research, or just for fun. I built a mobile game &lt;a href=&quot;https://github.com/bathompso/letterpress-solver&quot;&gt;&amp;quot;cheat&amp;quot; app&lt;/a&gt; in Python to practice when I was still improving my Python abilities, and learned a ton by Googling syntax the entire time. Don&amp;#39;t worry about going deep into optimizations of the language, just work on the basic problem of coding: translating a complex word problem into small steps that can be handled by code.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Know your basic statistics.&lt;/strong&gt; Brush up on z- and t-tests, and know what ANOVA is. Honestly, stats knowledge is not as necessary as most transition guides make it out to be, as the most stats that a data scientist will have to know will be to validate experimental A/B test results, or spot when a stats &lt;em&gt;faux pas&lt;/em&gt; has occurred. Beyond that, you really don&amp;#39;t need to be a wizard at stats, and I wouldn&amp;#39;t spend a ton of time on the subject.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Know basic machine learning techniques.&lt;/strong&gt; ML is another area that guides seem to believe you need a deep knowledge on, but this really depends on roles you&amp;#39;re interested in. If you&amp;#39;re going into a role that will be developing ML solutions (i.e. coding these solutions up and slowly improving them), then by all means start digging through &lt;a href=&quot;https://www.amazon.com/Elements-Statistical-Learning-Prediction-Statistics/dp/0387848576/ref=sr_1_1?ie=UTF8&amp;qid=1493101408&amp;sr=8-1&amp;keywords=elements+of+statistical+learning&quot;&gt;dense books&lt;/a&gt; and learning these algorithms from first principles. For most other data scientists, however, you&amp;#39;ll just be applying pre-defined techniques in &lt;em&gt;scikit-learn&lt;/em&gt;, and don&amp;#39;t need to know the nitty gritty details of loss functions, gradient descent, and other buzzwords. You should, however, know the high-level concepts of how each ML technique works (linear regression, logistic regression, decision trees, SVMs, random forests, k-mean clustering, to name a few), and more importantly, &lt;em&gt;know the assumptions&lt;/em&gt; of each model. Know what heteroscedasticity means.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Learn SQL.&lt;/strong&gt; While not a &amp;quot;real&amp;quot; programming language, SQL is an absolute necessity of any data scientist toolkit. There are a number of free tutorials on SQL, with practice questions, to get you up to speed. SQL is a pretty easy language, so if you know any others (as you should per the first tip in this list), SQL should come to you without any real problems.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;em&gt;&amp;quot;But Ben, why don&amp;#39;t you suggest I become an expert in any of the above topics?&amp;quot;&lt;/em&gt; The answer is that no data science job, especially one considering you fresh out of academia, would expect you to be an expert in anything, and it&amp;#39;s unrealistic to expect that even after a few months of studying. Coding, and data science in general, is something you learn by &lt;em&gt;doing&lt;/em&gt;, and so you can only get better when you get into a job and actually use these skills on a day-to-day basis.&lt;/p&gt;

&lt;p&gt;In fact, what you should sell in a cover letter or interview for a data science position shouldn&amp;#39;t be your domain knowledge in these subject areas, but the fact that you are a Ph.D. One of the most valuable skills of a data scientist is being able to work independently on a complex problem, and be self-sufficient enough to work around problems that arise. These are basic principles of a Ph.D. research project, so anyone reading this guide should have no problem with that. When I evaluate candidates, I don&amp;#39;t really care about years of experience, but instead I look at what projects they accomplished. If they have a track record of delivering solutions to complex problems, I know they can learn the necessary coding, stats, ML, or SQL if they currently don&amp;#39;t know it.&lt;/p&gt;

&lt;h2&gt;What other guides won&amp;#39;t tell you.&lt;/h2&gt;

&lt;p&gt;Now to the lesser-talked-about necessities of a transition. While the above tips (and most you&amp;#39;ll see other places) focus on things you can learn or do during the transition, there are a number of things required in a data scientist that aren&amp;#39;t as easily learned from a book.&lt;/p&gt;

&lt;h3&gt;Communication&lt;/h3&gt;

&lt;p&gt;In academia, you&amp;#39;re surrounded by others very similar to you. When you go to a conference or talk, everyone there presumably &amp;quot;speaks the same language&amp;quot; and you can go deep into technical jargon without being too worried about putting off the audience. In industry this is often not the case. In my job, I interface directly with non-technical people all the time, and it&amp;#39;s up to me to distill my analysis and models into understandable terms to communicate my findings. Delivering quality reports is one of the most-necessary skills for a data scientist, and candidates without those skills will have a tough time passing interviews for most DS positions.&lt;/p&gt;

&lt;p&gt;The problem here is that it&amp;#39;s difficult to learn better communication and speaking habits from books, but instead must be practiced. So if you are still in your Ph.D., take every opportunity you have to speak at conferences to practice. Also try and speak within your department, taking time to distill your complex research project and findings to an undergraduate level. When you&amp;#39;re done with the talk, ask the undergrads whether they understood everything, and slowly improve your presentation via their feedback. If you can communicate your findings to them, you&amp;#39;ll be pretty close to having the skills necessary to translate your ML and analysis results to project managers and executives in an industry role.&lt;/p&gt;

&lt;h3&gt;Timelines&lt;/h3&gt;

&lt;p&gt;Another huge difference (which can often be a selling point to some people) is the vastly different timelines between academia and industry. In academia, you focus multiple years of work into a singular project, often with months of largely no progress while you work on gathering data or increasing the performance of various tests or algorithms. In industry, you&amp;#39;re at almost the other side of the spectrum, having to juggle multiple projects on very short turn-arounds.&lt;/p&gt;

&lt;p&gt;Because of this, you&amp;#39;re often having to iterate quickly to a 70% solution, and unable to wrangle the time to improve it to the 100% solution. Early in my data science career, I was juggling two to three projects at a time, often on a days-to-weeks timescale. This was an abrupt change, and required quick and dirty solutions I was not accustomed to during my Ph.D. It was difficult at first to accept that this was the &amp;quot;quality&amp;quot; of work I was putting out, but I slowly came to terms with it. I have adjusted accordingly and now function fine within these confines, but forsaking the &amp;quot;true academic&amp;quot; tendency to put out a perfect solution is something you have to make sure you&amp;#39;re prepared for.&lt;/p&gt;

&lt;p&gt;While this type of work environment isn&amp;#39;t something you can easily understand beforehand, I&amp;#39;ve attempted to come up with a way to &amp;quot;simulate&amp;quot; what this would be like:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Find two datasets on &lt;a href=&quot;https://www.kaggle.com/datasets&quot;&gt;Kaggle&lt;/a&gt; that interest you, and define a business problem you want to solve with each.&lt;/strong&gt; Some datasets already have apparent business questions they can answer, like &lt;a href=&quot;https://www.kaggle.com/tiredgeek/predict-bo-trial&quot;&gt;this dataset&lt;/a&gt; that asks &amp;quot;Can you predict product backorders?&amp;quot; For those datasets which don&amp;#39;t have immediate business questions created, try and think of a business that might produce this data for you, and why they might want a data scientist to analyze it.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Take a weekend and fully answer both questions.&lt;/strong&gt; Give yourself two full days to fully analyze both problems. Download and clean the data, do some exploratory analysis, and build a model (if necessary for the business case). Focus your efforts on solving the business case, and delivering a solution to the question you asked in Step 1.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Write blog posts explaining your methodology and results.&lt;/strong&gt; Why did you choose the model type that you did? What should the business learn from the data? What would the next steps be for the business on this project? Utilize some of the plots you generated during your data exploration phase. These blog posts should also be completely written in the weekend you&amp;#39;re doing the data work (which will make the time go by a bit faster).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;At the end of the weekend, post both blog posts online.&lt;/strong&gt; Everything is on the honor system, but no matter far you got on both questions, post your analysis code and blogs online at the end of the weekend. Send it to some friends and get their feedback on how well you communicated everything, and whether you justified your analysis choices clearly enough. Think about how you feel about the quality of work you did in the amount of time allotted. Did you spend too much time on one question, and not enough on the other? Did you feel like both problems were rushed? What would you improve if you had another two days?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Two full Kaggle datasets in two days is &lt;em&gt;hard&lt;/em&gt;, and I doubt you&amp;#39;ll get to a perfect solution you can be happy with for both, but that&amp;#39;s fine. While most DS jobs will have longer timescales than one day, this simulates some of the stress and time-management that you&amp;#39;ll encounter in an industry role, and figuring out how you handle it is important in determining whether you&amp;#39;ll be happy in data science. If you found yourself unhappy that you couldn&amp;#39;t spend the entire weekend (and the following weekend) on one of these projects because you found it super interesting and wanted to improve your model performance, then you might need to come to terms with whether you&amp;#39;ll be happy when industry timelines come to crash your party. There are certainly more &amp;quot;academic&amp;quot; timescale DS positions, and knowing what type of work culture you&amp;#39;re able to thrive in is important as you start looking for opportunities.&lt;/p&gt;

&lt;h3&gt;Expectations&lt;/h3&gt;

&lt;p&gt;Everyone coming to data science transition guides seem to assume that they&amp;#39;ll be happy in data science, but that&amp;#39;s not necessarily the case. While data science is the hot industry right now, and many people become lured in by the promise of working on cool machine learning or AI problems, a vast majority of DS roles don&amp;#39;t focus much of their time on those things. Lots of DS projects are more product analytics focus, which requires mining various data sources to determine user behavior, or detect trends via simple heuristics. These types of investigations can sometimes be intellectually rewarding and impactful, but aren&amp;#39;t necessarily earth-shattering in their complexity.&lt;/p&gt;

&lt;p&gt;Even in a ML project, only a small amount of time is actually spent training the model, but instead invested in data cleaning, exploration and iterative feature engineering. This work is arduous and tedious, but is absolutely necessary for moving onto the &amp;quot;fun&amp;quot; parts. The problem with learning data science via kaggle datasets and competitions is that the data is usually already cleaned for you, and the number of features fairly small. In practice, the data is much messier and feature space near limitless.&lt;/p&gt;

&lt;p&gt;At Uber, I work with billions of mobile app events coming in every day, and have to distill this waterfall of data into a smaller bucket of features that relate to the project at hand. This requires days of SQL writing to clean and transform the data into a large number of possibly-related features, a few hours of sanity-checking these pipelines to ensure the data makes sense, and then a few more hours of slowly iterating from a huge feature list into only a few impactful ones. After I&amp;#39;ve built my model, it&amp;#39;s spending another hour or two writing up everything and distilling it into a presentation or document outlining the entire process, and what learnings we can take from it (even if it&amp;#39;s just a black-box model we deploy to production). While this may be a week or two of work, only a very small slice of it is spent dealing with differing models or advanced tech explorations.&lt;/p&gt;

&lt;h2&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;I don&amp;#39;t want to be a downer, because data science can be a very interesting field, and I&amp;#39;m extremely happy I transitioned from academia. However, leaving academia because you&amp;#39;re unhappy to go into an industry where you&amp;#39;re equally as unhappy isn&amp;#39;t a good solution either. Most guides focus on what you can &lt;em&gt;learn&lt;/em&gt;, but I also think they should focus on what you can &lt;em&gt;expect&lt;/em&gt;. My best advice beyond the Kaggle time crunch challenge above is to seek out friends or others who have interesting business data, but no analyst, and tell them you want to give them free DS work. Do an actual project, with an actual client, and see whether you enjoy the intellectual challenge. If you do, then most likely you can find a role in DS that you will enjoy and be happy in. If you don&amp;#39;t like it, then try and see whether there are roles that only have aspects of the project you did enjoy, or perhaps re-think whether data science is the right career path for you.&lt;/p&gt;

&lt;p&gt;Any other &amp;quot;hidden&amp;quot; tips you&amp;#39;d want to share with other academics looking to transition? Let me know in the comments.&lt;/p&gt;
</description>
        <pubDate>Mon, 24 Apr 2017 00:00:00 -0700</pubDate>
        <link>http://localhost:4000/blog/hidden-transition-tips/</link>
        <guid isPermaLink="true">http://localhost:4000/blog/hidden-transition-tips/</guid>
        
        <category>Data Science</category>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>Setting Up Flask on AWS</title>
        <description>&lt;p&gt;&lt;em&gt;I recently completed the &lt;a href=&quot;http://insightdatascience.com&quot;&gt;Insight Data Science&lt;/a&gt; program, which involved the creation of a data science project from ideation through deployment (if interested, you can see my Insight project &lt;a href=&quot;http://respawninto.bathompso.com&quot;&gt;here&lt;/a&gt;). For deployment, a &lt;a href=&quot;http://flask.pocoo.org&quot;&gt;Flask webapp&lt;/a&gt; was created, and Amazon Web Services (AWS) was used to host it. I found that getting this all set up was one of the hardest things for fellows to accomplish, and recognized a few areas in which it could be improved.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;The instructions below are an attempt to improve the instructions for getting a Flask webapp up and running on AWS. While I assume no prior knowledge of Flask, I do no go into any Flask basics here, but that may be a blog post for the future. I will try to go slowly through the steps, and offer plentiful code examples and screenshots. This guide will hopefully serve as a better reference for future Insight sessions.&lt;/em&gt;&lt;/p&gt;

&lt;h2&gt;Creating an AWS Instance&lt;/h2&gt;

&lt;p&gt;First, we must create an AWS virtual machine to copy our files to, and serve our website. To get started, head to &lt;a href=&quot;http://aws.amazon.com&quot;&gt;aws.amazon.com&lt;/a&gt; and click the sign up button in the top right. Then, follow the steps to either sign into your existing Amazon.com account, or create a new one.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/generated/aws_flask/start_page-940x408-5779e3.png&quot; class=&quot;blogtextimg&quot; &gt;&lt;/p&gt;

&lt;p&gt;Unfortunately, I already went through the signup process, so I could not recreate some of the screens. I know you will have to enter your credit card information, but don&amp;#39;t worry, we will only be using the free AWS tier, so you will not be charged. I believe AWS will also ask you what region you want your servers to be in. For convenience, select one of the western US options (I chose Oregon).&lt;/p&gt;

&lt;p&gt;After completing signup, you will be presented with the AWS console screen, with all the products AWS has to offer. What we want to select is EC2, or Elastic Compute Cloud, the first option in the top left.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/generated/aws_flask/console-940x302-25fa0f.png&quot; class=&quot;blogtextimg&quot; &gt;&lt;/p&gt;

&lt;p&gt;After selecting EC2, you will be presented with the EC2 console screen, which can also be overwhelming with the number of options to choose from. To get started, select the &amp;quot;Instances&amp;quot; tab on the left sidebar (under the Instances subheader), which will take you to the following screen:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/generated/aws_flask/instances-940x371-79618d.png&quot; class=&quot;blogtextimg&quot; &gt;&lt;/p&gt;

&lt;p&gt;I already have an instance created for my project, but the list you will see will be empty. Press the blue &amp;quot;Launch Instance&amp;quot; button to set up a new virtual machine for your project. You will immediately be asked to select an operating system, and you should select the &amp;quot;Ubuntu Server&amp;quot; option. As of this writing, the current version is 14.04, but these instructions should still work on future versions.&lt;/p&gt;

&lt;p&gt;Next, you will select what type of instance you wish to create. For the free tier, there is only 1 option available, but there are many beefier virtual machines you could create if you wish to pay for the performance.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/generated/aws_flask/instance_type-940x422-3a4f4d.png&quot; class=&quot;blogtextimg&quot; &gt;&lt;/p&gt;

&lt;p&gt;Continue through the setup, just clicking the blue continue buttons, until you reach the review step. At this stage, AWS will ask you to create a &amp;quot;key pair,&amp;quot; that you will use to SSH into your instance.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/generated/aws_flask/key_pair-719x537-848b59.png&quot; class=&quot;blogtextimg&quot; &gt;&lt;/p&gt;

&lt;p&gt;Give it any name you wish (&amp;quot;aws&amp;quot; might be a good name), and click the &amp;quot;Download Key Pair&amp;quot; button. This will download a text file which contains the SSH key necessary to access the instance. &lt;strong&gt;Make sure to back this key file up!&lt;/strong&gt; If you ever lose your key file, you will not be able to enter your instance. Your data will be recoverable, but it will be hassle, and should be avoided at all costs.&lt;/p&gt;

&lt;p&gt;Once the key is downloaded, click the &amp;quot;Launch Instances&amp;quot; button, which should now be available.&lt;/p&gt;

&lt;h2&gt;Setting Up SSH&lt;/h2&gt;

&lt;p&gt;Before we worry about setting our files up on the instance, we should make sure we have easy access to log into the machine.&lt;/p&gt;

&lt;p&gt;First, we need to determine where our virtual machine is. To find your instance&amp;#39;s IP address, click back to the &amp;quot;Instances&amp;quot; tab, and select your instance. In the bottom right will list the IP address of the machine:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/generated/aws_flask/instance_ip-940x735-e6bf36.png&quot; class=&quot;blogtextimg&quot; &gt;&lt;/p&gt;

&lt;p&gt;We can now use this IP address to log in via SSH. Normally, the login requires a lengthy SSH command:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;div class=&quot;shell&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;ssh -i ~/Downloads/keyfile.pem ubuntu@ip.address.here&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;These commands get even more unwieldy when you try to copy files with &lt;code&gt;scp&lt;/code&gt; or create port tunnels (more on that later). To simplify all future steps, we will create an SSH alias.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Within your home folder is a hidden directory, &lt;code&gt;.ssh&lt;/code&gt;. Within this directory are all the configuration files for SSH connections. As a first step, copy your downloaded &lt;code&gt;*.pem&lt;/code&gt; file to the &lt;code&gt;~/.ssh&lt;/code&gt; directory. *Note: on a Mac, the key is sometimes downloaded as a &lt;code&gt;.pem.txt&lt;/code&gt; file. Remove the &lt;code&gt;.txt&lt;/code&gt; extension before copying.&lt;/li&gt;
&lt;li&gt;&lt;p&gt;We will also need to change the permissions of the downloaded &lt;code&gt;*.pem&lt;/code&gt; file. The key must be unreadable by other users in order to be considered; if it is readable by others it may pose a security risk. To alter the permissions, use the &lt;code&gt;chmod&lt;/code&gt; function: 
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;div class=&quot;shell&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;chmod &lt;span class=&quot;m&quot;&gt;600&lt;/span&gt; ~/.ssh/keyfile.pem&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Now that the key file is in the right location, and with the right permissions, we can create our alias. to do this, we want to edit the &lt;code&gt;~/.ssh/config&lt;/code&gt; file, which may or may not already exist on your system. Simply run &lt;code&gt;emacs ~/.ssh/config&lt;/code&gt; (or another editor of your choice) to create / edit the file. Add the following entry, substituting the IP address of your instance, and the exact name of your key file:
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;div class=&quot;shell&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Host aws
    HostName &lt;span class=&quot;m&quot;&gt;52&lt;/span&gt;.11.150.208
    User ubuntu
    Port &lt;span class=&quot;m&quot;&gt;22&lt;/span&gt;
    IdentityFile ~/.ssh/aws.pem&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Once the steps are complete, open a new terminal window, and you should be able to access your machine via the simple command:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;div class=&quot;shell&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;ssh aws&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;If this command fails for any reason, double check you completed steps 1 and 2, or troubleshoot the given error (perhaps you entered the wrong name for your keyfile, etc.). Once you can log into your machine, we can proceed.&lt;/p&gt;

&lt;h2&gt;Setting Up The Instance&lt;/h2&gt;

&lt;p&gt;When you enter the instance, it is essentially a blank slate: only a bare-bones Python installation, no packages, and no Flask. We will install the basic components necessary to get a dummy Flask app running before copying over any completed project you may have working locally.&lt;/p&gt;

&lt;p&gt;Python is already installed, but none of the add-on packages. We will want to speed up this process with &lt;code&gt;pip&lt;/code&gt;. It can be installed via:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;div class=&quot;shell&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;sudo apt-get update
sudo apt-get install python-pip&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;These commands will do a &lt;em&gt;bunch&lt;/em&gt; of things, and exit with &lt;code&gt;pip&lt;/code&gt; now installed for use. Next, we will install Flask to get our bare-bones dummy example working&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;div class=&quot;shell&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;sudo pip install flask&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;The &lt;code&gt;$PYTHONPATH&lt;/code&gt; variable seems to get unset randomly, and causes errors for later steps. To avoid this, add the following line to the top of your &lt;code&gt;~/.bashrc&lt;/code&gt; file:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;div class=&quot;shell&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;export&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;PYTHONPATH&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;/usr/lib/python2.7:/usr/lib/python2.7/plat-x86_64-linux-gnu:/usr/lib/python2.7/lib-tk:/usr/lib/python2.7/lib-old:/usr/lib/python2.7/lib-dynload:/usr/local/lib/python2.7/dist-packages:/usr/lib/python2.7/dist-packages:/usr/lib/python2.7/dist-packages/PILcompat&amp;#39;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h2&gt;Creating a Dummy Flask App&lt;/h2&gt;

&lt;p&gt;To create a dummy Flask app, you will need to run the following commands to create the directory structure:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;div class=&quot;shell&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;mkdir dummyapp
mkdir dummyapp/app
mkdir dummyapp/app/static
mkdir dummyapp/app/templates&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;This will create a folder, &lt;code&gt;dummyapp&lt;/code&gt;, which will contain all the pieces of our dummy Flask application. A similar process can be followed to put your project webapp into a single folder.&lt;/p&gt;

&lt;p&gt;Next, we will create the necessary python and HTML files for our skeleton app. Remember, to create any file, simply run &lt;code&gt;emacs [filename]&lt;/code&gt;, or any other command line text editor. The names of the following files will be the first line of the code, in a comment:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;div class=&quot;pyfile&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# dummyapp/app/__init__.py&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;flask&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Flask&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;app&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Flask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;vm&quot;&gt;__name__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;app&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;views&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;div&gt;&amp;nbsp;&lt;/div&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;div class=&quot;pyfile&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# dummyapp/app/views.py&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;flask&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;render_template&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;app&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;app&lt;/span&gt;

&lt;span class=&quot;nd&quot;&gt;@app.route&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;/&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;returnDict&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{}&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;returnDict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;user&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;Ben&amp;#39;&lt;/span&gt;    &lt;span class=&quot;c1&quot;&gt;# Feel free to put your name here!&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;returnDict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;title&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;Home&amp;#39;&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;render_template&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;index.html&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;returnDict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;div&gt;&amp;nbsp;&lt;/div&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-html&quot; data-lang=&quot;html&quot;&gt;&lt;div class=&quot;pyfile&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c&quot;&gt;&amp;lt;!-- dummyapp/app/templates/index.html --&amp;gt;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;html&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;p&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;head&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;gt;&lt;/span&gt;{{ title }} - microblog&lt;span class=&quot;p&quot;&gt;&amp;lt;/&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;p&quot;&gt;&amp;lt;/&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;head&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;p&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;body&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;h1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;gt;&lt;/span&gt;Hello, {{ user }}!&lt;span class=&quot;p&quot;&gt;&amp;lt;/&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;h1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;p&quot;&gt;&amp;lt;/&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;body&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;gt;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;&amp;lt;/&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;html&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;div&gt;&amp;nbsp;&lt;/div&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;div class=&quot;pyfile&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;app&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;app&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;app&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Once all the files are in place, you should be able to run the app with &lt;code&gt;python run.py&lt;/code&gt; from the main &lt;code&gt;~/dummyapp/&lt;/code&gt; folder. However, the default port 5000 is blocked, so you won&amp;#39;t be able to see it from the outside. To do this, logout of the virtual machine and create a port tunnel &lt;em&gt;from your local machine&lt;/em&gt;:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;div class=&quot;shell&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;ssh -L &lt;span class=&quot;m&quot;&gt;5000&lt;/span&gt;:localhost:5000 aws&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;This command takes port 5000 on your local machine, &lt;code&gt;localhost&lt;/code&gt;, and binds it to port 5000 on &lt;code&gt;aws&lt;/code&gt;. It also SSH&amp;#39;s to &lt;code&gt;aws&lt;/code&gt; so that you can run the dummy Flask app from there. Running it this time, and navigating your browser to &lt;code&gt;localhost:5000&lt;/code&gt; should give you the &amp;quot;Hello [Name]&amp;quot; message, and you should see a line print in your terminal from a generic &lt;code&gt;GET&lt;/code&gt; command. Once you&amp;#39;ve verified the dummy app is working, we can move onto making it persistent.&lt;/p&gt;

&lt;h2&gt;Installing Nginx&lt;/h2&gt;

&lt;p&gt;To keep our Flask app running constantly and make sure it can serve a decent number of concurrent users, we will use Nginx, a webserver. It will handle passing traffic from your instance to the Flask web process. To install it, simply run:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;div class=&quot;shell&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;sudo apt-get install nginx&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Once installed, the webserver is automatically running. To check whether it&amp;#39;s working, we&amp;#39;ll have to open up the necessary ports to pass HTTP requests to the virtual machine. To do this, go back to the EC2 console and select the &amp;quot;Security Groups&amp;quot; option in the sidebar, select your instance, then click the &amp;quot;Inbound&amp;quot; tab at the bottom of the page.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/generated/aws_flask/security_group-940x725-b8f19f.png&quot; class=&quot;blogtextimg&quot; &gt;&lt;/p&gt;

&lt;p&gt;Click the &amp;quot;Edit&amp;quot; button in the Inbound tab, then add a new rule. Select HTTP from the dropdown menu, and it will automatically open port 80 on your virtual machine.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/generated/aws_flask/http_rule-873x408-a11671.png&quot; class=&quot;blogtextimg&quot; &gt;&lt;/p&gt;

&lt;p&gt;Once the port has been opened, navigate your browser to your instance&amp;#39;s IP address, and you should be greeted by an Nginx welcome message. This message means that the webserver is working, and is ready to be hooked into your Flask app.&lt;/p&gt;

&lt;h2&gt;Configuring uWSGI&lt;/h2&gt;

&lt;p&gt;To hook flask into Nginx, we will be using the python package uWSGI. uWSGI is an alternate web process from the default one used by Flask that makes it easier to connect to Nginx. Unfortunately, the &lt;code&gt;pip&lt;/code&gt; installation of this module always seems to fail, so we use &lt;code&gt;apt-get&lt;/code&gt; instead:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;div class=&quot;shell&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;sudo apt-get install uwsgi-core uwsgi-plugin-python&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Next, we need to make a configuration file so that uWSGI knows the parameters of the Flask app it is serving. To do this, we create a parameter file, which usually has the &lt;code&gt;.ini&lt;/code&gt; suffix. For our example, we can create a &lt;code&gt;uwsgi.ini&lt;/code&gt; file in the &lt;code&gt;dummyapp/&lt;/code&gt; folder, containing the following:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;div class=&quot;shell&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;uwsgi&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;home&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; /home/ubuntu/dummyapp
wsgi-file &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; %&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;home&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;/run.py
&lt;span class=&quot;nv&quot;&gt;socket&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;127&lt;/span&gt;.0.0.1:3033
&lt;span class=&quot;nv&quot;&gt;callable&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; app
&lt;span class=&quot;nv&quot;&gt;module&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; app
&lt;span class=&quot;nv&quot;&gt;plugin&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; python
&lt;span class=&quot;nv&quot;&gt;pythonpath&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; %&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;home&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;daemonize&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; %&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;home&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;/dummyapp.log
&lt;span class=&quot;nv&quot;&gt;pidfile&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; %&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;home&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;/dummyapp.pid&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Before moving on, I will explain some of the options above:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;home&lt;/code&gt; defines the home directory of the app. This becomes a variable in some of the other options.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;wsgi-file&lt;/code&gt; defines the file that should be run to start the web process. This is, for almost everyone, &lt;code&gt;run.py&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;socket&lt;/code&gt; defines a port on the virtual machine that will pass information between uWSGI and nginx. The port number can be almost anything, as long as it is not used by another program. I recommend using ports 3301-3306, which should be unused by anything else.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;module&lt;/code&gt; defines the name of the folder containing views and templates, in most cases &lt;code&gt;app/&lt;/code&gt;. If you name your folder something else, change this entry to that name.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;daemonize&lt;/code&gt; defines the path to the log file for the Flask app. All lines printed to the console during a normal run of your app will be printed to this file instead. This will allow you to see any error messages or diagnostic print statements in your code.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;pidfile&lt;/code&gt; defines the path to a file containing the process ID of the uWSGI process. This file will be used to stop the server when something needs to be changed.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Once the uWSGI configuration file is finished, we will have to configure nginx to accept traffic from uWSGI. The configuration file for nginx is located at &lt;code&gt;/etc/nginx/nginx.conf&lt;/code&gt;. First, we need to break nginx&amp;#39;s hold on port 80 (the welcome message you see), and allow uWSGI and Flask to use it. To do this, comment out lines 71 and 72, which should be the first two uncommented lines after a giant commented block.&lt;/p&gt;

&lt;p&gt;Next, we need to tell nginx where to look when it gets traffic from outside sources. Below the lines you just commented out, and still within the &lt;code&gt;html&lt;/code&gt; block, add the following:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;div class=&quot;shell&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;server &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    listen &lt;span class=&quot;m&quot;&gt;80&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    location / &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        include uwsgi_params&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
        uwsgi_pass &lt;span class=&quot;m&quot;&gt;127&lt;/span&gt;.0.0.1:3033&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;This tells nginx to &amp;quot;listen&amp;quot; on port 80 (the default HTTP port), and pass all that information to uWSGI on port 3033 (make sure to change this port to whatever you specified in the config file).&lt;/p&gt;

&lt;p&gt;Now that we have updated nginx to use the correct parameters, we need to restart it so it re-reads the config file. Do this with:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;div class=&quot;shell&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;sudo service nginx restart&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;You should see an &lt;code&gt;[OK]&lt;/code&gt; message, which means that nginx was restarted successfully. Now we need to start the uWSGI process to finish everything off. To do this, simply run:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;div class=&quot;shell&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;uwsgi ~/dummyapp/uwsgi.ini&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Now if you point your browser to the IP address of your instance, you should see the hello message from your dummy Flask app. If you do, &lt;strong&gt;congrats, you&amp;#39;re (almost) done!&lt;/strong&gt;. If not, check the log file (&lt;code&gt;~/dummyapp/dummyapp.log&lt;/code&gt;) to see what problems have arisen. Google those error messages to troubleshoot. To stop the uWSGI process, run:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;div class=&quot;shell&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;uwsgi --stop ~/dummyapp/dummyapp.pid&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Now that you had a dummy app working, you can begin to copy over your completed app. Make sure to test it before starting into deployment. Run the app interactively first, by calling the &lt;code&gt;run.py&lt;/code&gt; file and checking to see if there are any errors. Most likely, you will have to install many supporting python packages, or recreate your database before the app will run, without complicating the process with uWSGI and nginx.&lt;/p&gt;

&lt;p&gt;After the app is working locally, make sure to create a tunnel on port 5000 and play around with using it. Make sure the app behaves in a reasonable manner, as you will be able to see the error messages easily. Once you&amp;#39;ve confirmed that most functionality is working, recreate the uWSGI configuration file, and start the uWSGI process.&lt;/p&gt;

&lt;h2&gt;Notes&lt;/h2&gt;

&lt;p&gt;One import note on uWSGI is that it does not reload upon changes to your Flask app. If you copy down a new version from github, or make edits to the code locally, you will have to stop and start the uWSGI process for the changes to become live. While this seems strange at first, it is helpful if you accidentally mess something up; your live app won&amp;#39;t see the issue, and you&amp;#39;ll have time to fix things, or roll back, if necessary.&lt;/p&gt;

&lt;p&gt;Nginx allows you to do many advanced and nice things, such as subdomains. If your main site is running at &lt;code&gt;example.com&lt;/code&gt;, you would be able to create another flask app, pass it through a different port to nginx, and serve that app on &lt;code&gt;another.example.com&lt;/code&gt;. This allows you to use your single AWS instance for a whole host of side projects, which is not possible with other Flask web servers.&lt;/p&gt;

&lt;p&gt;Hopefully this walkthrough was easy to follow and understand, and you now have at least a dummy app, but your full project working on AWS. In the near future, I&amp;#39;ll be adding a few more Flask and AWS tricks to this blog, so stay tuned.&lt;/p&gt;
</description>
        <pubDate>Sat, 21 Mar 2015 00:00:00 -0700</pubDate>
        <link>http://localhost:4000/blog/flask-aws-setup/</link>
        <guid isPermaLink="true">http://localhost:4000/blog/flask-aws-setup/</guid>
        
        <category>Data Science</category>
        
        <category>Insight</category>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>Data-Mining Destiny</title>
        <description>&lt;p&gt;Stuff.&lt;/p&gt;

&lt;div id=&quot;level_plot&quot; class=&quot;highcharts_plot&quot; style=&quot;width: 100%;&quot;&gt;&lt;/div&gt;

&lt;div id=&quot;grimoire_plot&quot; class=&quot;highcharts_half&quot;&gt;&lt;/div&gt;&lt;div id=&quot;glimmer_plot&quot; class=&quot;highcharts_half&quot;&gt;&lt;/div&gt;

&lt;div style=&quot;float: left;&quot;&gt;
    &lt;div class=&quot;zoompie_title pietriple&quot;&gt;Subclass Breakdown&lt;/div&gt;
    &lt;div id=&quot;subclass&quot; class=&quot;zoompie pietriple&quot;&gt;&amp;nbsp;&lt;/div&gt;
    &lt;div id=&quot;subclass_legend&quot; class=&quot;zoompie_legend pietriple&quot;&gt;&amp;nbsp;&lt;/div&gt;
&lt;/div&gt;

&lt;div style=&quot;float: left;&quot;&gt;
    &lt;div class=&quot;zoompie_title pietriple&quot;&gt;Race Breakdown&lt;/div&gt;
    &lt;div id=&quot;race&quot; class=&quot;zoompie pietriple&quot;&gt;&amp;nbsp;&lt;/div&gt;
    &lt;div id=&quot;race_legend&quot; class=&quot;zoompie_legend pietriple&quot;&gt;&amp;nbsp;&lt;/div&gt;
&lt;/div&gt;

&lt;div style=&quot;float: left;&quot;&gt;
    &lt;div class=&quot;zoompie_title pietriple&quot;&gt;# of Characters&lt;/div&gt;
    &lt;div id=&quot;nchar&quot; class=&quot;zoompie pietriple&quot;&gt;&amp;nbsp;&lt;/div&gt;
    &lt;div id=&quot;nchar_legend&quot; class=&quot;zoompie_legend pietriple&quot;&gt;&amp;nbsp;&lt;/div&gt;
&lt;/div&gt;

&lt;div style=&quot;clear:both&quot;&gt;&amp;nbsp;&lt;/div&gt;

&lt;div style=&quot;float: left;&quot;&gt;
    &lt;div class=&quot;zoompie_title piedouble&quot;&gt;Weapon Type Breakdown&lt;/div&gt;
    &lt;div id=&quot;weap&quot; class=&quot;zoompie piedouble&quot;&gt;&amp;nbsp;&lt;/div&gt;
    &lt;div id=&quot;weap_legend&quot; class=&quot;zoompie_legend piedouble&quot;&gt;&amp;nbsp;&lt;/div&gt;
&lt;/div&gt;

&lt;div style=&quot;clear:both&quot;&gt;&amp;nbsp;&lt;/div&gt;

&lt;div style=&quot;float: left;&quot;&gt;
    &lt;div class=&quot;zoompie_title piedouble&quot;&gt;Exotic Weapon Breakdown&lt;/div&gt;
    &lt;div id=&quot;exweap&quot; class=&quot;zoompie piedouble&quot;&gt;&amp;nbsp;&lt;/div&gt;
    &lt;div id=&quot;exweap_legend&quot; class=&quot;zoompie_legend piedouble&quot;&gt;&amp;nbsp;&lt;/div&gt;
&lt;/div&gt;

&lt;div style=&quot;float: left;&quot;&gt;
    &lt;div class=&quot;zoompie_title piedouble&quot;&gt;Exotic Armor Breakdown&lt;/div&gt;
    &lt;div id=&quot;exarmor&quot; class=&quot;zoompie piedouble&quot;&gt;&amp;nbsp;&lt;/div&gt;
    &lt;div id=&quot;exarmor_legend&quot; class=&quot;zoompie_legend piedouble&quot;&gt;&amp;nbsp;&lt;/div&gt;
&lt;/div&gt;

&lt;div style=&quot;clear:both&quot;&gt;&amp;nbsp;&lt;/div&gt;
</description>
        <pubDate>Fri, 06 Mar 2015 00:00:00 -0800</pubDate>
        <link>http://localhost:4000/notblog/destiny/</link>
        <guid isPermaLink="true">http://localhost:4000/notblog/destiny/</guid>
        
        <category>Data Science</category>
        
        
        <category>notblog</category>
        
      </item>
    
      <item>
        <title>#AAS225 and What's Next</title>
        <description>&lt;p&gt;For those of you who know me personally (or follow me on Twitter), you know that I am currently in Seattle for the American Astronomical Society (AAS) meeting. Tomorrow I&amp;#39;ll be doing a dissertation talk, distilling the entirety of my work at TCU over the past 4 years into a overly-short 15 minute presentation. After the conference, however, I will not be getting on a plane back to DFW, but will instead be headed just a bit down the west coast to San Francisco. I &lt;a href=&quot;/blog/transition-to-data-science/&quot;&gt;previously wrote&lt;/a&gt; about how academia was heading for a breakdown and many scientists were turning to industry for employment. Now I&amp;#39;m one of those scientists.&lt;/p&gt;

&lt;p&gt;Instead of heading back home, I will be living in Palo Alto, CA for 3 months while I attend the &lt;a href=&quot;http://insightdatascience.com&quot;&gt;Insight Data Science Program&lt;/a&gt;. Insight is a 3-month training program that looks for hard-science Ph.D. that wish to transition into the data science industry in Silicon Valley. From what I&amp;#39;ve heard from people at the AAS, it is a very exclusive club, and is extolled by those who know somebody who previously attended. &lt;/p&gt;

&lt;p&gt;The first six weeks of the program involves all of the necessary programming training for a job in the industry. I will pick a public data set and complete an analysis similar to one I would do in a data science job. For the second six weeks, I will interview at top tech companies who sponsor the program: companies like Facebook, LinkedIn, Microsoft, and Jawbone (you can see a full list of the awesome places I could end up on the &lt;a href=&quot;http://insightdatascience.com&quot;&gt;Insight home page&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;Attending the conference this week has only solidified my choice to transition into data science. Reading posters on topics completely unrelated to my area of expertise got me excited simply due to the interesting results they achieved. It cemented the fact that I enjoy tackling new challenges and learning new things, regardless of the subject matter I&amp;#39;m working with. I am just as happy to study binary systems (my current area), as I am starspots, or galaxy simulations, or website user data. As long as I&amp;#39;m able to satisfy my curiosity to explore the world around me through data, I will be happy.&lt;/p&gt;

&lt;p&gt;While 2014 was an amazing year for me (I got married!), I believe 2015 will be the best yet. I&amp;#39;m extremely excited for the opportunity to be a part of this highly-regarded program, and thankful to have found a solid path forward after grad school. I will be back in DFW on April 1st, when I&amp;#39;ll defend my Ph.D., and then Chrissy and I will leave sometime in mid- to late May to head out for San Francisco full time.&lt;/p&gt;

&lt;p&gt;Although I haven&amp;#39;t been using it much lately, this blog will be more active while I&amp;#39;m in the program. I&amp;#39;ll be sharing my experiences, as well as the new things I&amp;#39;ve learned, hoping that it might help the next lost astrophysicist (or biologist, or economist, etc.). Look for more good stuff in the coming weeks.&lt;/p&gt;
</description>
        <pubDate>Wed, 07 Jan 2015 00:00:00 -0800</pubDate>
        <link>http://localhost:4000/blog/aas225/</link>
        <guid isPermaLink="true">http://localhost:4000/blog/aas225/</guid>
        
        <category>Research</category>
        
        <category>Data Science</category>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>10.3: OpenCL</title>
        <description>&lt;p&gt;Recently, there has been another revolution in computing power: the use of graphical processing units (GPUs) in general computation. For quite a while, GPUs have been used for heavy computation: rendering and drawing the complex shapes that appear on your monitor. As computer graphics became more sophisticated (animations, transitions, gaming), GPUs became more and more powerful. To handle the enourmous amount of computation involved in rendering a computer game (drawing millions of tiny polygons), GPUs began to add more and more processing units. While each processing unit ran at a small fraction of the speed of a CPU, many advanced GPUs included hundreds (or thousands!) of these units, giving GPUs (generally) more overall processing power than a CPU.&lt;/p&gt;

&lt;p&gt;Instead of tasking these GPU units to draw shapes to the screen, we can instead use them for general computation using &lt;a href=&quot;http://www.khronos.org/opencl/&quot;&gt;OpenCL&lt;/a&gt;. OpenCL is a programming framework for massively parallel computing using &lt;strong&gt;any&lt;/strong&gt; computation device (CPU or GPU). While other GPU frameworks exist (most notably &lt;a href=&quot;http://www.nvidia.com/object/cuda_home_new.html&quot;&gt;nVidia&amp;#39;s CUDA&lt;/a&gt;), OpenCL is an open standard that supports all types of CPUs and GPUs. Intel, nVidia and AMD are all partners of OpenCL, making the technology compatible with all their products.&lt;/p&gt;

&lt;p&gt;In this section we will learn how to harness the massively-parallel architecture of your GPU for use in your Python programs.&lt;/p&gt;

&lt;h2&gt;10.3.1 PyOpenCL Installation&lt;/h2&gt;

&lt;p&gt;The OpenCL Python module we will use is &lt;a href=&quot;http://mathema.tician.de/software/pyopencl/&quot;&gt;PyOpenCL&lt;/a&gt;. Other options exist, but I have found this module to have great documentation, which is important when learning new techniques. There are several steps involved in installing this module:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;PyOpenCL requires the boost C++ libraries. You can install them via homebrew: &lt;code&gt;brew install boost&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://pypi.python.org/pypi/pyopencl&quot;&gt;Download the PyOpenCL source&lt;/a&gt; and unpack it.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;cd&lt;/code&gt; into the unpacked directory and build the required binaries: &lt;code&gt;python setup.py build&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Install the package: &lt;code&gt;sudo python setup.py install&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;These steps &lt;em&gt;should&lt;/em&gt; complete without any issues. Once everything is installed, re-open your terminal window and start python. Test if the module is installed by typing &lt;code&gt;import pyopencl&lt;/code&gt;.&lt;/p&gt;

&lt;h2&gt;10.3.2 OpenCL Algorithms&lt;/h2&gt;

&lt;p&gt;For the most part, programs leveraging the OpenCL framework are similar to those using PP, as described above. You want to &lt;strong&gt;write your heavy computation into a function that will be called many time via a loop&lt;/strong&gt;. However, the code to create this function, and the &amp;quot;job server&amp;quot; that handles it, is much different. Before we delve into the code, let&amp;#39;s go over how OpenCL moves your computations and data around:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;The function that will handle the parallel computation (called a &lt;em&gt;kernel&lt;/em&gt;) is compiled on the computing device. This computing device may be different than your primary CPU.&lt;/li&gt;
&lt;li&gt;Your data is imported into your main Python program, and resides in system memory.&lt;/li&gt;
&lt;li&gt;Your computing device, if it is not your main CPU, &lt;em&gt;cannot&lt;/em&gt; access system memory. Before the kernel can be run, we have to copy the necessary data to the device&amp;#39;s memory.&lt;/li&gt;
&lt;li&gt;Your computing device runs the kernel, crunching the numbers and producing results. These results reside in the device memory.&lt;/li&gt;
&lt;li&gt;To access the results in your main Python code, we must copy the results from device memory to system memory.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Before each run of the kernel we will have to copy over all necessary data, and after each run we will have to copy back the results. For most basic programs you won&amp;#39;t have to think hard about this data transfer. For more advanced programs, however, there are two opposing concepts to consider:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Data transfer takes time. While you will still gain massive improvements over a serial code, many copies to and from device memory can add significant overhead.&lt;/li&gt;
&lt;li&gt;Most GPUs have limited memory. My MacBook Pro&amp;#39;s graphics memory is only 256MB, miniscule in the face of the 8GB of system memory, and most of that memory is already absorbed by running the display. This means that transfers of large arrays of data may fail due to insufficient memory size.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;You will have to balance these two issues when deisgning a program. If you need to run a parallel analysis on a large array, do you copy the entire thing over to the GPU at once, or do you break it down into smaller pieces? Sometimes you will have to experiment with how much data your specific device can handle, and modify your algorithms appropriately.&lt;/p&gt;

&lt;h2&gt;10.3.3 OpenCL Kernels&lt;/h2&gt;

&lt;p&gt;The OpenCL kernel is the main program that runs the parallel computation. As OpenCL is a fairly low-level framework, it is mostly written for the C and FORTRAN programming languages, not Python. As such, the PyOpenCL kernel &lt;strong&gt;must be written in C&lt;/strong&gt;. This is a deviation from everything we have learned previously in the course, but only a slight one. As programming languages essentially work the same way, and therefore it will be easy to translate from Python into C.&lt;/p&gt;

&lt;p&gt;There are many quirks and differences between writing a Python subroutine and an OpenCL kernel, but the best way to learn is by looking at already-written programs and discussing. Below are two examples of PyOpenCL kernels, and we will walk through the main points of each.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Kernel Example 1: Vector Addition:&lt;/strong&gt; The kernel below takes in two vectors and adds them together.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c--&quot; data-lang=&quot;c++&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__kernel&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;vadd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__global&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;__global&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;__global&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;unsigned&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;get_global_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;div style='clear:both'&gt;&lt;/div&gt;

&lt;p&gt;Let&amp;#39;s go over some of the main structure here:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Every kernel will start with &lt;code&gt;__kernel void&lt;/code&gt;. This is because &lt;strong&gt;kernels do not return any values&lt;/strong&gt;. You will notice that vector &lt;code&gt;c&lt;/code&gt; is the resulting vector, and it is used as an input into the function. This is true for all OpenCL kernels, and you will have to create an empty vector to save your calculation results to when you write your own OpenCL kernels.&lt;/li&gt;
&lt;li&gt;Vector inputs are specified as &lt;code&gt;__global [datatype]*&lt;/code&gt;, while scalar inputs are specified as &lt;code&gt;const [datatype]&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Parallel computations are called multiple times via a loop. &lt;code&gt;get_global_id(0)&lt;/code&gt; gets the counter from the loop. In OpenCL, it is possible to have a multi-dimensional loop, and each loop index is pulled from the vector &lt;code&gt;get_global_id&lt;/code&gt;. So programs with a 3D loop may have &lt;code&gt;get_global_id(0)&lt;/code&gt;, &lt;code&gt;get_global_id(1)&lt;/code&gt;, and &lt;code&gt;get_global_id(2)&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;You may be wondering why we are passing the length of the vectors &lt;code&gt;count&lt;/code&gt; to the kernel. This is because &lt;strong&gt;C does not have a built-in way of finding the length of vectors&lt;/strong&gt;. If you have a loop over a vector, it is best to either hard-code the vector length into the kernel (if it will always be the same), or pass the length as a variable, as is done here.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;Kernel Example 2: Matrix Multiplication:&lt;/strong&gt; The kernel below takes in two matrices and multiplies them together.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c--&quot; data-lang=&quot;c++&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__kernel&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;mmul&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Mdim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Ndim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Pdim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;__global&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;__global&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;B&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;__global&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;C&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;get_global_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;get_global_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;kt&quot;&gt;float&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tmp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Ndim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Mdim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;tmp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Pdim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;tmp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Ndim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;B&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Pdim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;C&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Ndim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tmp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;div style='clear:both'&gt;&lt;/div&gt;

&lt;p&gt;We see all of the concepts mentioned in the vector addition case here as well: matrix dimensions are passed as variables into the code, and the counters from this 2D loop are pulled from &lt;code&gt;get_global_id&lt;/code&gt;. The only thing new may be the treatment of the matrices themselves. In Python, you would specify a matrix element via &lt;code&gt;A[i,k]&lt;/code&gt;, but here there is only one index. This is because &lt;strong&gt;C cannot handle multi-dimensional arrays&lt;/strong&gt;. When passing a 2D+ array into an OpenCL kernel, you will have to transform it to a 1D vector, as is done here.&lt;/p&gt;

&lt;p&gt;The last thing you may need to know about OpenCL kernels is that advanced (and even basic) math functions may not be available. If you have done any basic C or C++ programming, you know that most often you need to import the &lt;code&gt;math.h&lt;/code&gt; or &lt;code&gt;&amp;lt;cmath&amp;gt;&lt;/code&gt; headers to get access to most math functions beyond simple addition and multiplication. In OpenCL versions 1.1 and below, this header is not supported, and you lose out on all of these functions. In OpenCL 1.2+, however, &lt;code&gt;math.h&lt;/code&gt; is imoported by default, and you can use any of the functions available there.&lt;/p&gt;

&lt;h2&gt;10.3.4 PyOpenCL Syntax&lt;/h2&gt;

&lt;p&gt;Now that we know how to write our OpenCL kernels, we need to merge them into our Python programs. There are lots of parts to this, so the easiest thing to do is look at an example. Let&amp;#39;s look at the full Python routine for the vector addition example:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# Import modules&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pyopencl&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;cl&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;np&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Specify kernel&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;kernelsource&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class=&quot;s2&quot;&gt;__kernel void vadd(&lt;/span&gt;
&lt;span class=&quot;s2&quot;&gt;    __global float* a,&lt;/span&gt;
&lt;span class=&quot;s2&quot;&gt;    __global float* b,&lt;/span&gt;
&lt;span class=&quot;s2&quot;&gt;    __global float* c,&lt;/span&gt;
&lt;span class=&quot;s2&quot;&gt;    const unsigned int count)&lt;/span&gt;
&lt;span class=&quot;s2&quot;&gt;{&lt;/span&gt;
&lt;span class=&quot;s2&quot;&gt;    int i = get_global_id(0);&lt;/span&gt;
&lt;span class=&quot;s2&quot;&gt;    if (i &amp;lt; count)&lt;/span&gt;
&lt;span class=&quot;s2&quot;&gt;        c[i] = a[i] + b[i];&lt;/span&gt;
&lt;span class=&quot;s2&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;s2&quot;&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Set-Up OpenCL environment&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;context&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;create_some_context&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;    &lt;span class=&quot;c1&quot;&gt;# Choose Device&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;queue&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CommandQueue&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;    &lt;span class=&quot;c1&quot;&gt;# Create Command Queue&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;program&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Program&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kernelsource&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;build&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Build Kernel&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;vadd&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;program&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vadd&lt;/span&gt;                  &lt;span class=&quot;c1&quot;&gt;# Build Program&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;vadd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;set_scalar_arg_dtypes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;uint32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Set program variable types&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Create input vectors&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;h_a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rand&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;astype&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;float32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;h_b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rand&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;astype&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;float32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Copy input vectors to device&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;d_a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Buffer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mem_flags&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;READ_ONLY&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mem_flags&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;COPY_HOST_PTR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hostbuf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;h_a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;d_b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Buffer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mem_flags&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;READ_ONLY&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mem_flags&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;COPY_HOST_PTR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hostbuf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;h_b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Create output vector&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;h_c&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;astype&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;float32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Copy output vector to device&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;d_c&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Buffer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mem_flags&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;WRITE_ONLY&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h_c&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nbytes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Execute kernel&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;vadd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;queue&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h_a&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d_a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d_b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d_c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Read back results from the compute device&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;cl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;enqueue_copy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;queue&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h_c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d_c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;div style='clear:both'&gt;&lt;/div&gt;

&lt;p&gt;The list below will walk through each of the commented lines and explain what is happening in that region of the code.&lt;/p&gt;

&lt;h3&gt;Setting up the OpenCL environment:&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Import modules&lt;/strong&gt;: At minimum you must import PyOpenCL and NumPy into your program.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Specify kernel&lt;/strong&gt;: This is the same kernel that we saw in the example before, but enclosed in triple quotations (&amp;quot;&amp;quot;&amp;quot;) and saved as a string variable. This string will be passed to PyOpenCL later in the code and built on the computing device.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Choose device&lt;/strong&gt;: The &lt;code&gt;create_some_context()&lt;/code&gt; command will set up a computing environment on the specified computing device. If a machine has more than one possible options (a CPU and GPU), the user will be asked which device they wish to use.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Create command queue&lt;/strong&gt;: Similar to PP, PyOpenCL creates a command queue which passes loop iterations to idle cores on the computing device.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Build kernel&lt;/strong&gt;: The &lt;code&gt;cl.Program&lt;/code&gt; command takes the computing environment and compiles the kernel on it.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Build program&lt;/strong&gt;: The kernel string may specify more than one program (you may have subroutines for the kernel. This line specifies which function within the kernel string should be fed the input values.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Set program variable types&lt;/strong&gt;: While you have specified the expected data types in the kernel, PyOpenCL must know how to format the input data so that everything matches up between devices. Vector inputs have a variable type of &lt;code&gt;None&lt;/code&gt;, while scalar data types are specified using the NumPy variable classifications. (In this example, we are passing an unsigned 32-bit integer).&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;Creating and copying data:&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Create input vectors&lt;/strong&gt;: This is mostly stuff you have seen before. We create a vector of random numbers (although we could import the data from anywhere) to be input into the program. The only difference is the &lt;code&gt;.astype(np.float32)&lt;/code&gt;. This is because OpenCL (at least earlier versions of it) cannot handle the standard 64-bit floating point numbers that NumPy uses by default. If we passed a 64-bit float array to the OpenCL kernel, the memory locations would not line up, and we would get garbage results. Make sure to convert any arrays you are passing to OpenCL to 32-bit variables (float, int, uint, or otherwise).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Copy input vectors to device&lt;/strong&gt;: As stated in 10.3.2, the computing device cannot access system memory, and variables must be copied to the computing device before running the kernel. The variable &lt;code&gt;hostbuf&lt;/code&gt; is the input vector that was generated in Python, and the output is the new device array. You will notice two memory flags are set for input vectors: &lt;code&gt;READ_ONLY&lt;/code&gt; and &lt;code&gt;COPY_HOST_PTR&lt;/code&gt;. &lt;code&gt;READ_ONLY&lt;/code&gt; means that the vector is an input value and should not be changed. &lt;code&gt;COPY_HOST_PTR&lt;/code&gt; means that we want to copy out the memory reference position of the vector to the computing device. Both of these memory flags should be set for any vector being copied to the computing device&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Create output vector&lt;/strong&gt;: We need to make a placeholder for the output vector we expect. Here we simply specify a &lt;code&gt;np.zeros&lt;/code&gt; of the same length as the inputs, making sure to convert it to a &lt;code&gt;np.float32&lt;/code&gt; type as well.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Copy output vector to device&lt;/strong&gt;: You will notice that the memory flags for this command are &lt;code&gt;WRITE_ONLY&lt;/code&gt;, which makes sense considering we want to be able to modify this array when printing results. The &lt;code&gt;cl.Buffer&lt;/code&gt; call is slightly different in the fact that we pass it the number of bytes that &lt;code&gt;h_c&lt;/code&gt; takes up, as opposed to passing the pointer (like we did for the inputs). This is because we are simply &lt;em&gt;creating the space for the results in the computing device&amp;#39;s memory&lt;/em&gt;, not really copying anything there.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;Executing the kernel and returning results:&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Execute kernel&lt;/strong&gt;: Now that everything is copied to the computing device, we can run the kernel on all the data. The &lt;code&gt;vadd()&lt;/code&gt; command takes several arguments:

&lt;ul&gt;
&lt;li&gt;The first argument of the &lt;code&gt;vadd()&lt;/code&gt; command is the command queue.&lt;/li&gt;
&lt;li&gt;The second is the &amp;quot;shape&amp;quot; of the loop that should be run. Remmber, we get the increment of the loop within the kernel via the &lt;code&gt;get_global_id&lt;/code&gt; function; the second argument specifies that array. In the example, we are passing the &amp;quot;shape&amp;quot; of our 1D input vector, meaning that we will have a 1D loop of length 1000.&lt;/li&gt;
&lt;li&gt;The third argument is the data type of the kernel&amp;#39;s return values. As kernels will not return data, this is always &lt;code&gt;None&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;The last arguments are the input values into the &lt;code&gt;vadd&lt;/code&gt; kernel. Remember, we need to pass the &lt;em&gt;copied&lt;/em&gt; vector inputs and outputs to the program for it to work properly. Scalar values do not have to be copied, and can be specified using their current names in the Python program.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Copying results&lt;/strong&gt;: Once the kernel is complete, the results vector still resides on the computing device. To copy it back, we use the &lt;code&gt;cl.enqueue_copy&lt;/code&gt; command to move the device&amp;#39;s results (&lt;code&gt;d_c&lt;/code&gt;) back to the Python program&amp;#39;s vector (&lt;code&gt;h_c&lt;/code&gt;).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;After copying back the results from the kernel, your Python program can continue as normal. To help you get a further grip on writing OpenCL programs, let us also look over the matrix multiplication example we saw in 10.3.3:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# Import modules&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pyopencl&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;cl&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;np&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Specify kernel&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;kernelsource&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class=&quot;s2&quot;&gt;__kernel void mmul(&lt;/span&gt;
&lt;span class=&quot;s2&quot;&gt;   const int Mdim,&lt;/span&gt;
&lt;span class=&quot;s2&quot;&gt;   const int Ndim,&lt;/span&gt;
&lt;span class=&quot;s2&quot;&gt;   const int Pdim,&lt;/span&gt;
&lt;span class=&quot;s2&quot;&gt;   __global float* A,&lt;/span&gt;
&lt;span class=&quot;s2&quot;&gt;   __global float* B,&lt;/span&gt;
&lt;span class=&quot;s2&quot;&gt;   __global float* C)&lt;/span&gt;
&lt;span class=&quot;s2&quot;&gt;{&lt;/span&gt;
&lt;span class=&quot;s2&quot;&gt;   int k;&lt;/span&gt;
&lt;span class=&quot;s2&quot;&gt;   int i = get_global_id(0);&lt;/span&gt;
&lt;span class=&quot;s2&quot;&gt;   int j = get_global_id(1);&lt;/span&gt;
&lt;span class=&quot;s2&quot;&gt;   float tmp;&lt;/span&gt;
&lt;span class=&quot;s2&quot;&gt;   if ((i &amp;lt; Ndim) &amp;amp;&amp;amp; (j &amp;lt; Mdim))&lt;/span&gt;
&lt;span class=&quot;s2&quot;&gt;   {&lt;/span&gt;
&lt;span class=&quot;s2&quot;&gt;       tmp = 0.0;&lt;/span&gt;
&lt;span class=&quot;s2&quot;&gt;       for (k = 0; k &amp;lt; Pdim; k++)&lt;/span&gt;
&lt;span class=&quot;s2&quot;&gt;           tmp += A[i*Ndim+k] * B[k*Pdim+j];&lt;/span&gt;
&lt;span class=&quot;s2&quot;&gt;       C[i*Ndim+j] = tmp;&lt;/span&gt;
&lt;span class=&quot;s2&quot;&gt;   }&lt;/span&gt;
&lt;span class=&quot;s2&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;s2&quot;&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Set-Up OpenCL environment&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;context&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;create_some_context&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;    &lt;span class=&quot;c1&quot;&gt;# Choose Device&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;queue&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CommandQueue&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;    &lt;span class=&quot;c1&quot;&gt;# Create Command Queue&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;program&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Program&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kernelsource&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;build&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Build Kernel&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;mmul&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;program&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mmul&lt;/span&gt;                  &lt;span class=&quot;c1&quot;&gt;# Build Program&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;mmul&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;set_scalar_arg_dtypes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;uint32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;uint32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;uint32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Set program variable types&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Set up matrix sizes&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Ndim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Pdim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Mdim&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;500&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;600&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;700&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sizeA&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Ndim&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Pdim&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sizeB&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Pdim&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Mdim&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sizeC&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Ndim&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Mdim&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Create input matrices&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;h_a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rand&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sizeA&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;astype&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;float32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;h_b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rand&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sizeB&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;astype&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;float32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Copy input matrices to device&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;d_a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Buffer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mem_flags&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;READ_ONLY&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mem_flags&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;COPY_HOST_PTR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hostbuf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;h_a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;d_b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Buffer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mem_flags&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;READ_ONLY&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mem_flags&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;COPY_HOST_PTR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hostbuf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;h_b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Create output matrix&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;h_c&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sizeC&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;astype&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;float32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Copy output matrix to device&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;d_c&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Buffer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mem_flags&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;WRITE_ONLY&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h_c&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nbytes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Execute kernel&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;loopshape&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Ndim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Mdim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;mmul&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;queue&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loopshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Mdim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Ndim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Pdim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d_a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d_b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d_c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Read back results from the compute device&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;cl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;enqueue_copy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;queue&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h_c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d_c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;div style='clear:both'&gt;&lt;/div&gt;

&lt;p&gt;Almost everything here is the same as in the vector addition example, with the only difference being the &lt;code&gt;loopshape&lt;/code&gt; variable. In this example we have a 2D loop (over every element in array &lt;code&gt;h_c&lt;/code&gt;), with the &amp;quot;shape&amp;quot; defined by &lt;code&gt;loopshape&lt;/code&gt;. In general you can make the shape of the loop any dimension by specifying more elements in the &lt;code&gt;loopshape&lt;/code&gt; list. You will also notice that our &amp;quot;matrices&amp;quot; are actually arrays with the same number of elements. Matrix &lt;code&gt;h_a&lt;/code&gt; should have a size of \( 500 \times 600 \), but instead is a 300,000 element vector. This is due to the fact that OpenCL can only handle 1D vectors instead of 2D matrices.&lt;/p&gt;

&lt;p&gt;These two examples cover much of what you need to know about how to write OpenCL programs. The clever part is figuring out which parts of the code can be parallelized, and how you can manipulate your algorithms to fit within the confines of the OpenCL limitations (no &lt;code&gt;math.h&lt;/code&gt; header, no matrices, etc.).&lt;/p&gt;
</description>
        <pubDate>Fri, 03 Oct 2014 00:00:00 -0700</pubDate>
        <link>http://localhost:4000/education/compphys/parallel/opencl/</link>
        <guid isPermaLink="true">http://localhost:4000/education/compphys/parallel/opencl/</guid>
        
        
        <category>education</category>
        
        <category>compphys</category>
        
        <category>parallel</category>
        
      </item>
    
      <item>
        <title>10.2: ParallelPython</title>
        <description>&lt;p&gt;One of the first transistions into the parallel computing age was the introduction of multi-core and multi-thread CPUs. Originally, CPUs could only compute a single task at a time, but with the addition of multiple cores they could handle several at once. In this section we will explore how to write Python programs that can use all available CPU cores / threads on your machine.&lt;/p&gt;

&lt;h2&gt;10.2.1 Installation&lt;/h2&gt;

&lt;p&gt;Stock Python (including the modules used so far) do not allow Python to take advantage of multi-core architecture. Instead, we must download and install another module, called (imaginatively) ParallelPython. This can be done via the built-in &lt;code&gt;pip&lt;/code&gt; installer, with some nudging. ParallelPython is not hosted on the same repository &lt;code&gt;pip&lt;/code&gt; usually downloads from, so you&amp;#39;ll have to allow for using external and unverified sources to find it.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span&gt;&lt;/span&gt;sudo pip install pp --allow-external pp --allow-unverified pp&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;After successful installation, you should be able to access all ParallelPython (PP) routines by importing the module via&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pp&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;div style='clear:both'&gt;&lt;/div&gt;

&lt;h2&gt;10.2.2 Running Parallel Tasks With ParallelPython&lt;/h2&gt;

&lt;h3&gt;The JobServer&lt;/h3&gt;

&lt;p&gt;Everything in PP is run through the JobServer. The JobServer reads the tasks that are passed to it and doles them out to idle cores on the machine. Before we can run anything in parallel, we must initialize the JobServer. You can do this via the line:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;job_server&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pp&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Server&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;div style='clear:both'&gt;&lt;/div&gt;

&lt;p&gt;There are several optional keywords that can be specified for the PP job server:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;# of Cores&lt;/strong&gt;: by default, PP will use all available cores in your machines. In all the examples here, I am using a MacBook Pro with a quad-core i7 processor which implements Hyper-Threading, meaning that each core can process 2 threads simultaneously. With 4 cores and 2 threads per core, PP can use a maximum of 8 simultaneous computations. If you wish to use less than the maximum, you can enter that value into the &lt;code&gt;Server&lt;/code&gt; command.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Networked Machines&lt;/strong&gt;: PP is not only meant for doing parallel computations on your local machines, but distributing itself across an entire network of machines to handle massive computations. If you have other machines with PP installed that you want to network to to help with computations, enter their IP addresses as the keyword &lt;code&gt;ppservers&lt;/code&gt; in the &lt;code&gt;Server&lt;/code&gt; command.&lt;/p&gt;

&lt;p&gt;With both options enabled, the JobServer initialization command will look like:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;job_server&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pp&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Server&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ppservers&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;10.0.0.1&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;10.0.0.2&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;div style='clear:both'&gt;&lt;/div&gt;

&lt;h3&gt;Submitting Jobs&lt;/h3&gt;

&lt;p&gt;Now that the JobServer is created, we can begin passing tasks to it using the &lt;code&gt;.submit()&lt;/code&gt; function. A PP &lt;code&gt;.submit()&lt;/code&gt; call will look like:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;job_server&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;submit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;subroutine&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;var1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;var2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;func2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;func3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;modname&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,))&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;div style='clear:both'&gt;&lt;/div&gt;

&lt;p&gt;There are several parts to this call:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;subroutine&lt;/code&gt;: The first variable of the &lt;code&gt;.submit()&lt;/code&gt; function is the name of the subroutine function that is being iterated multiple times.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;var1, var2&lt;/code&gt;: The second variable of the &lt;code&gt;.submit()&lt;/code&gt; function is a list of the variables that are necessary for function &lt;code&gt;subroutine&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;func2, func3&lt;/code&gt;: The third variable of the &lt;code&gt;.submit()&lt;/code&gt; function is a list of the functions (if any) on which the subroutine depends.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;modname&lt;/code&gt;: The last variable fo the &lt;code&gt;.submit()&lt;/code&gt; function is a list of module names necessary for the subroutine function. If the subroutine uses any modules, you will not be able to specify a shortname. So if your subroutine depends on &lt;code&gt;numpy&lt;/code&gt;, make sure to write functions as &lt;code&gt;numpy.cos&lt;/code&gt; instead of the regular shorthand, &lt;code&gt;np.cos&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Why does &lt;code&gt;.submit()&lt;/code&gt; require these inputs?&lt;/strong&gt; The answer is in what exactly ParallelPython does. For each submitted job, PP essentially &lt;em&gt;writes a new Python code&lt;/em&gt; which runs the specified function. all the variables necessary (variables, dependent functions and modules) are necessary for creating a standalone program to execute. PP then runs this function on the next available idle core. The result returned from this function will be stored in the result variable you specify.&lt;/p&gt;

&lt;h3&gt;Multiple Jobs&lt;/h3&gt;

&lt;p&gt;The code above will submit a single job and return a single value, but that isn&amp;#39;t the point of parallel computing, and is an egregious waste of computer resources. Instead, we want to submit multiple instances of the subroutine function, then analyze the multiple results coming back. To do this, we simply wrap the previous &lt;code&gt;submit()&lt;/code&gt; command in a for loop.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inputvals&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;results&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;job_server&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;submit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;subroutine&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;math&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,))&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;input&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inputvals&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;div style='clear:both'&gt;&lt;/div&gt;

&lt;p&gt;Here, &lt;code&gt;results&lt;/code&gt; will be a 5-element list with the results of the &lt;code&gt;subroutine&lt;/code&gt; function for each of the input values.&lt;/p&gt;

&lt;p&gt;Unlike normal Python, which waits for the previous command to finish before moving on, a &lt;code&gt;.submit()&lt;/code&gt; call spawn a new process, send it to an idle core (if available) and immediately moves on. This will only stop when the program needs to access the results. As a consequence, PP routines can produce unexpected results. If you ran, for example:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inputvals&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;results&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;job_server&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;submit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;subroutine&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;math&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,))&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;input&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inputvals&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;PARALLEL RESULTS:&amp;quot;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;results&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;!!!  &amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span&gt;&lt;/span&gt;PARALLEL RESULTS:
!!!  &lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;div style='clear:both'&gt;&lt;/div&gt;

&lt;p&gt;The output in the above example would appear immediately after running the program, with a long wait to finish computing all the results before finishing the print statement loop. While this isn&amp;#39;t a logic or arithmetic error, it does produce strange-looking results for the user of your program. If you wish to &amp;quot;pretty up&amp;quot; the output, you can simply add a non-printing loop after the submit function to make sure all results are complete:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;results&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tmp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;div style='clear:both'&gt;&lt;/div&gt;

&lt;p&gt;This loop adds little overhead to the entire program, but makes sure that all parallel runs have returned results before moving on to printing statements or other analysis steps that &lt;em&gt;may&lt;/em&gt; be affected by the non-serialized completion. To access the results of a PP run, all variables must have an empty parentheses pair, as seen in the above two examples.&lt;/p&gt;

&lt;h2&gt;10.2.3 Example: Finding Primes in Parallel&lt;/h2&gt;

&lt;p&gt;Earlier in the course, we discussed how to easily (and in a brute-force manner) determine if a number was prime or not. Now, imagine that we want to determine the number of primes less than a certain value (say 10,000). This is easy to do. First, we start with our (already-written) prime-determining function.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;isprime&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Look for factors &amp;lt;= sqrt(n)&lt;/span&gt;
    &lt;span class=&quot;nb&quot;&gt;max&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;math&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ceil&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;math&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;# We found a factor. Number is not prime.&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# This number is not a factor, move to the next one&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# We found no factors &amp;lt;= sqrt(n), this is a prime.&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;div style='clear:both'&gt;&lt;/div&gt;

&lt;p&gt;Using this function, we can write a new function, &lt;code&gt;findprimes&lt;/code&gt;, which will call isprime for all numbers less than the specified value.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;findprimes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;xrange&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;isprime&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;div style='clear:both'&gt;&lt;/div&gt;

&lt;p&gt;This very simple code loops through all values between 2 and n, and returns each value which returns True from &lt;code&gt;isprime&lt;/code&gt;.&lt;/p&gt;

&lt;h3&gt;Parallelization&lt;/h3&gt;

&lt;p&gt;Instead of running this loop normally, we instead will run it in parallel and see what benefit we gain. Below is the code that will compute the same results as &lt;code&gt;findprimes&lt;/code&gt;, but will do it with all available cores.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;math&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sys&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pp&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# [[ Function isprime definition ]]&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;maxval&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10000&lt;/span&gt;
    
&lt;span class=&quot;c1&quot;&gt;### SINGLE PROCESS RUN&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;start_time&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;findprimes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;maxval&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;SINGLE: There are&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;primes below&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;maxval&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;end_time&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;SINGLE Time elapsed:&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;end_time&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;start_time&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;### PARALLEL PROCESS RUN&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;start_time&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;job_server&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pp&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Server&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;Running with&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;job_server&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_ncpus&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;processes.&amp;quot;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;maxval&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;results&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;job_server&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;submit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;isprime&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;math&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,))&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;input&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;nprimes&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;results&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;PARALLEL: There are&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nprimes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;primes below&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;maxval&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;end_time&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;PARALLEL Time elapsed:&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;end_time&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;start_time&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span&gt;&lt;/span&gt;SINGLE: There are &lt;span class=&quot;m&quot;&gt;1229&lt;/span&gt; primes below &lt;span class=&quot;m&quot;&gt;10000&lt;/span&gt;
SINGLE Time elapsed: &lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;.0364170074463
Running with &lt;span class=&quot;m&quot;&gt;8&lt;/span&gt; processes.
PARALLEL: There are &lt;span class=&quot;m&quot;&gt;1229&lt;/span&gt; primes below &lt;span class=&quot;m&quot;&gt;10000&lt;/span&gt;
PARALLEL Time elapsed: &lt;span class=&quot;m&quot;&gt;4&lt;/span&gt;.32518792152&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;div style='clear:both'&gt;&lt;/div&gt;

&lt;p&gt;While parallel processes are usually faster than serial ones, the parallel routine takes almost 100x as long. This is due to the way that PP works: by writing an entirely new program for each new process and then running it on an unused core. This re-writing causes each new process (10,000 of them in the above example) to have to import the necessary modules as well as compile each of the new &amp;quot;codes.&amp;quot; Adding this overhead to so many small computations is not an effective use of parallelization.&lt;/p&gt;

&lt;p&gt;When writing a program that utilizes multiple processes, it is best to make sure that your routines actually helps instead of hurts your speed.&lt;/p&gt;

&lt;h2&gt;10.2.4 Growth of Primes&lt;/h2&gt;

&lt;p&gt;Using the two custom functions, &lt;code&gt;isprime&lt;/code&gt; and &lt;code&gt;findprimes&lt;/code&gt;, we can write a simple, parallelized function that will compute primes of various numbers. Keep in mind that the function findprimes itself will not be parallelized, but we can run multiple instances of findprimes at once to speed up alternate calculations. Because we need to run multiple instances of &lt;code&gt;findprimes&lt;/code&gt; for the parallelization to make sense, pretend we want to find how the number of primes less than a certain number grows. Here is our python program, excluding the two custom functions written out previously.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;math&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pp&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;time&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# [[ Function isprime and findprimes definitions ]]&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;### SINGLE PROCESS RUN&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;start_time&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;findprimes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1000000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;SINGLE: There are&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;primes below&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1000000&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;end_time&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;SINGLE Time elapsed:&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;end_time&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;start_time&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;### PARALLEL PROCESS RUN&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;job_server&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pp&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Server&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;Running with&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;job_server&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_ncpus&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;processes.&amp;quot;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;inputvals&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1000000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;start_time&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;results&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;job_server&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;submit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;findprimes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;isprime&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;math&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,)))&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;input&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inputvals&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;results&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;tmp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;There are&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()),&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;primes below&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;input&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;end_time&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;PARALLEL Time elapsed:&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;end_time&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;start_time&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span&gt;&lt;/span&gt;SINGLE: There are &lt;span class=&quot;m&quot;&gt;78498&lt;/span&gt; primes below &lt;span class=&quot;m&quot;&gt;1000000&lt;/span&gt;
SINGLE Time elapsed: &lt;span class=&quot;m&quot;&gt;13&lt;/span&gt;.4798531532
Running with &lt;span class=&quot;m&quot;&gt;8&lt;/span&gt; processes.
There are &lt;span class=&quot;m&quot;&gt;25&lt;/span&gt; primes below &lt;span class=&quot;m&quot;&gt;100&lt;/span&gt;
There are &lt;span class=&quot;m&quot;&gt;168&lt;/span&gt; primes below &lt;span class=&quot;m&quot;&gt;1000&lt;/span&gt;
There are &lt;span class=&quot;m&quot;&gt;1229&lt;/span&gt; primes below &lt;span class=&quot;m&quot;&gt;10000&lt;/span&gt;
There are &lt;span class=&quot;m&quot;&gt;9592&lt;/span&gt; primes below &lt;span class=&quot;m&quot;&gt;100000&lt;/span&gt;
There are &lt;span class=&quot;m&quot;&gt;78498&lt;/span&gt; primes below &lt;span class=&quot;m&quot;&gt;1000000&lt;/span&gt;
PARALLEL Time elapsed: &lt;span class=&quot;m&quot;&gt;13&lt;/span&gt;.3912439346&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;div style='clear:both'&gt;&lt;/div&gt;

&lt;p&gt;If you run this program, you will notice that the results are printed out as they are finished. You can also see that the parallel version of this code takes just as long as the serial case for &lt;code&gt;findprimes(1000000)&lt;/code&gt;, with all the other results coming essentially for free! For this and the example before, you can begin to understand the best uses for PP. Because the process-spawning sequence incurs a decent overhead, it is best to parallelize routines that require a fairly large amount of computation. That way the overhead becomes a very small percentage of each process&amp;#39; run time, and you gain much more when running multiple at once.&lt;/p&gt;
</description>
        <pubDate>Thu, 02 Oct 2014 00:00:00 -0700</pubDate>
        <link>http://localhost:4000/education/compphys/parallel/parallelpython/</link>
        <guid isPermaLink="true">http://localhost:4000/education/compphys/parallel/parallelpython/</guid>
        
        
        <category>education</category>
        
        <category>compphys</category>
        
        <category>parallel</category>
        
      </item>
    
      <item>
        <title>Lesson 10: Parallel Computing</title>
        <description>&lt;p&gt;Named after Intel co-founder Gordon Moore, &lt;a href=&quot;http://en.wikipedia.org/wiki/Moore%27s_law&quot;&gt;Moore&amp;#39;s law&lt;/a&gt; states that number of transistors on integrated circuits will double every 2 years. It should be noted that Moore&amp;#39;s law is an empirical observation, not a law of physics or nature. It has been estimated that, by 2015 growth will have slowed enough that transistor count will only double every 3 years.&lt;/p&gt;

&lt;p&gt;For programmers, Moore&amp;#39;s law was great. If your program ran too slow on your current hardware, all you had to do was wait two years, and it should run twice as fast on the newest chips.&lt;/p&gt;

&lt;p&gt;Around 2004, Moore&amp;#39;s law began to break down due to overheating within the chips. Packing a large amount of transistors onto small chips left little room for heat dissipation, causing increased failures. To keep up with the Moore&amp;#39;s law pace, chip makers expanded into multi-core architecture. By only slightly increasing the number of transistors per core, the overall chip could still keep pace.&lt;/p&gt;

&lt;p&gt;Unfortunately for programmers, it was no longer the case that you could wait 2 years and expect a double in performance. Now, you had to write your program to take advantage of the multiple cores that were provided by the hardware. Programming to take advantage of parallel computing requires a different type of thinking than everything that has been done previously in this class.&lt;/p&gt;

&lt;h2&gt;10.1 Introduction to Parallel Computing&lt;/h2&gt;

&lt;h3&gt;Parallel Computing Algorithms&lt;/h3&gt;

&lt;p&gt;Not all programs can be written to utilize parallel capabilities. Programs that are best suited are those that require many &lt;strong&gt;independent&lt;/strong&gt; iterations of a &lt;code&gt;for&lt;/code&gt; loop. These types of programs are good because individual iterations can be assigned to each of the different processing cores, unlike normal procedural codes where one operation depends on the results of a previous one. A few examples of easily parallelized programs are listed below:&lt;/p&gt;

&lt;h4&gt;Vector Addition&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;/generated/vadd-300x214-16fd8b.png&quot; class=&quot;lessontextimg&quot; &gt;&lt;/p&gt;

&lt;p&gt;When adding vectors, you are essentially looping over the vector and adding each component together. When writing a regular program, each of these element additions would happen in order, but there is no reason for that. When writing this as a parallel program, each element is assigned to a core, and completed in sequential order.&lt;/p&gt;

&lt;p&gt;The figure to the right illustrates how the parallel vector addition algorithm works. In this scenario, we are using a quad-core processor. The addition of elements 1-4 are assigned to each of the four cores. The first core to complete the addition is the assigned the 5th element, and so on until everything is complete.&lt;/p&gt;

&lt;h4&gt;Matrix Multiplication&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;/generated/mmult-300x214-4f4c10.png&quot; class=&quot;lessontextimg&quot; &gt;&lt;/p&gt;

&lt;p&gt;Another easily parallelizable problem is matrix multiplication. Each element of the resulting array is a multiplication of a single row and column of the input arrays. Each element’s value is independent of the others, and often this multiplication requires many iterations of a loop.&lt;/p&gt;

&lt;p&gt;The figure to the right shows how this problem would look in a parallel scenario. Where vector addition was a 1D loop, matrix multiplication is 2D. In the example, we are computing a \( 3\times N \) matrix product on a quad-core processor. The multiplication proceeds left-to-right and top-to-bottom, with element 2,1 being assigned to the 4th core. As multiplications are completed, the next element of the array is assigned to that core.&lt;/p&gt;

&lt;h4&gt;Algorithms&lt;/h4&gt;

&lt;p&gt;When writing programs to take full advantage of parallel computing resources, there are several things to consider:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Make sure loop iterations are independent.&lt;/em&gt; Because iterations are not necessary completed in order, you cannot expect that shared variables will be dealt with in an understandable way. There are methods that will allow for the &amp;quot;locking&amp;quot; of shared variables in parallel computation, but those will not be covered here.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Know what problem space you are dealing with.&lt;/em&gt; In the two examples above, each had different dimensions of loops. Vector addition requires only one dimension of looping, while matrix multiplication requires 2D. This will be an important factor in designing some parallel programs.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Make sure the program at hand is best suited for parallelization.&lt;/em&gt; It takes a decent bit longer to write and debug a parallelized code than it does a serial one. If your program includes a loop which is only run a few times (or can use other fast ways of handling in serial form), it may not be the best use of your time to write a parallel code. Often problems in physics will involve hundreds or thousands (sometimes hundreds of thousands) or iterations of a loop: these are programs that will benefit greatly from parallelization. In each of the following sections, we will time various parallel programs to see what (if any) speed improvements are made.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;&lt;a href=&quot;parallelpython/&quot;&gt;10.2 ParallelPython&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;One of the first transistions into the parallel computing age was the introduction of multi-core and multi-thread CPUs. Originally, CPUs could only compute a single task at a time, but with the addition of multiple cores they could handle several at once. In this section we will explore how to write Python programs that can use all available CPU cores / threads on your machine.&lt;/p&gt;

&lt;h2&gt;&lt;a href=&quot;opencl/&quot;&gt;10.3 OpenCL&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Recently, there has been another revolution in computing power: the use of graphical processing units (GPUs) in general computation. For quite a while, GPUs have been used for heavy computation: rendering and drawing the complex shapes that appear on your monitor. As computer graphics became more sophisticated (animations, transitions, gaming), GPUs became more and more powerful. To handle the enourmous amount of computation involved in rendering a computer game (drawing millions of tiny polygons), GPUs began to add more and more processing units. While each processing unit ran at a small fraction of the speed of a CPU, many advanced GPUs included hundreds (or thousands!) of these units, giving GPUs (generally) more overall processing power than a CPU.&lt;/p&gt;

&lt;p&gt;In this section we will learn how to harness the massively-parallel architecture of your GPU for use in your Python programs.&lt;/p&gt;
</description>
        <pubDate>Wed, 01 Oct 2014 00:00:00 -0700</pubDate>
        <link>http://localhost:4000/education/compphys/parallel/</link>
        <guid isPermaLink="true">http://localhost:4000/education/compphys/parallel/</guid>
        
        
        <category>education</category>
        
        <category>compphys</category>
        
      </item>
    
      <item>
        <title>Lesson 9: Database Systems</title>
        <description></description>
        <pubDate>Mon, 01 Sep 2014 00:00:00 -0700</pubDate>
        <link>http://localhost:4000/education/compphys/databases/</link>
        <guid isPermaLink="true">http://localhost:4000/education/compphys/databases/</guid>
        
        
        <category>education</category>
        
        <category>compphys</category>
        
      </item>
    
      <item>
        <title>Lesson 8: Monte Carlo Methods</title>
        <description></description>
        <pubDate>Fri, 01 Aug 2014 00:00:00 -0700</pubDate>
        <link>http://localhost:4000/education/compphys/random/</link>
        <guid isPermaLink="true">http://localhost:4000/education/compphys/random/</guid>
        
        
        <category>education</category>
        
        <category>compphys</category>
        
      </item>
    
      <item>
        <title>From Astronomy to Data Science: One Size Fits All?</title>
        <description>&lt;p&gt;Academia has been undergoing a crisis as of late. Many disciplines (even &amp;quot;hot ones,&amp;quot; such as &lt;a href=&quot;http://arstechnica.com/science/2014/04/is-us-biomedical-research-heading-for-a-breakdown/&quot;&gt;biomedical research&lt;/a&gt;) have been finding that they are producing too many short-term jobs (post-docs), and too few permanent positions to sustain the outflow of Ph.D.s.&lt;/p&gt;

&lt;p&gt;Astronomy (my chosen field), is no exception. Heaped on top of this is the fact that as the U.S. government tightens it&amp;#39;s belt, &amp;quot;pure science&amp;quot; budgets, such as those for NASA and NSF&amp;#39;s astronomy grants, are those removed first. As grant money earned is often a metric to determine tenure, this makes it even harder to keep a tenure-track job, if you somehow manage to get one in the first place.&lt;/p&gt;

&lt;p&gt;As I&amp;#39;ve come to terms with this, I&amp;#39;ve begun to look into alternative fields for a career, and data science is one I have seen a lot. But looking into the several &amp;quot;&lt;a href=&quot;http://womeninastronomy.blogspot.com/2013/01/datascience.html&quot;&gt;astronomer to data scientist&lt;/a&gt;&amp;quot; transition &lt;a href=&quot;http://womeninastronomy.blogspot.com/2013/01/astroVdatascience.html&quot;&gt;guides&lt;/a&gt; on the &lt;a href=&quot;http://betterbayes.wordpress.com/2014/07/24/preperation-for-a-transition-to-data-science/&quot;&gt;web&lt;/a&gt;, all seem to tell me the same thing: &amp;quot;learn lots of programming languages, like Python, R or SAS.&amp;quot; &amp;quot;Learn &lt;a href=&quot;http://en.m.wikipedia.org/wiki/NoSQL&quot;&gt;NoSQL&lt;/a&gt;, &lt;a href=&quot;http://hadoop.apache.org&quot;&gt;Hadoop&lt;/a&gt;, and &lt;a href=&quot;http://en.m.wikipedia.org/wiki/Mapreduce&quot;&gt;MapReduce&lt;/a&gt;.&amp;quot; In short, these guides seem to think every data science job is the same: a &amp;quot;big data&amp;quot; scientist at a Silicon Valley startup or tech titan.&lt;/p&gt;

&lt;p&gt;If somebody was preparing for a career in physics and asked you what they should learn to prepare, you wouldn&amp;#39;t necessarily be able to answer. Interested in computational astrophysics? You&amp;#39;ll need to know C or FORTRAN to write highly parallelized codes that run on supercomputers. Interested in engineering? You probably don&amp;#39;t need to spend your time learning general relativity. &amp;quot;Physics&amp;quot; isn&amp;#39;t one thing, and therefore you can&amp;#39;t just prepare in a single way. Data science is exactly the same.&lt;/p&gt;

&lt;p&gt;Instead of prescribing preparation steps for a very specific job, below are some general tips I&amp;#39;ve found in my time exploring the data science market, that everyone should definitely do.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Do some reading on general data science principles.&lt;/strong&gt; Regardless of what subsection of data science you want to go into, everyone should be well-versed in the &amp;quot;fundamental principles.&amp;quot; &lt;a href=&quot;http://www.amazon.com/Data-Science-Business-data-analytic-thinking/dp/1449361323/&quot;&gt;Data Science for Business&lt;/a&gt; is an excellent book on this topic, and I suggest everyone read through it. Not only will it give you an outline of many of the basic data science algorithms, but really hammers in the fact that data science &lt;em&gt;is part of business, not a hard science&lt;/em&gt;. Everything you do should be to further the business goals.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Decide whether data science is really what you want.&lt;/strong&gt; In the last bullet of her &lt;a href=&quot;http://womeninastronomy.blogspot.com/2013/01/astroVdatascience.html&quot;&gt;&amp;quot;Astronomy vs Data Science&amp;quot; post&lt;/a&gt;, Jessica Kirkpatrick states that you cannot dictate the subject matter in industry like you can in academia. As stated above, everything you do in data science should be to further the business goals. This can be an adjustment, as in academia you pick a subject largely unconstrained by others. Make sure this is a trade-off you&amp;#39;re okay with.&lt;br&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;For me, I enjoy taking (often incomplete) data and telling a story with it. It doesn&amp;#39;t matter what I&amp;#39;m looking at: star brightnesses to determine masses or customer location history to detect fraud, I enjoy any time I am &amp;quot;learning&amp;quot; something. For others, this may not be the case. No matter the benefits of a data science career (salary, locations, job security), doing something you don&amp;#39;t enjoy isn&amp;#39;t the way to go.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Decide what section of data science you want to enhabit.&lt;/strong&gt; Does working for Google or Facebook tracking millions (or billions) of users&amp;#39; behaviors online sound exciting? How about &lt;a href=&quot;http://ars.to/1zc3H6r&quot;&gt;data mining thousands of healthy people&amp;#39;s DNA to improve healthcare&lt;/a&gt;? Maybe you &lt;em&gt;should&lt;/em&gt; look into the &amp;quot;Silicon Valley Big Data&amp;quot; jobs. Maybe you&amp;#39;d like to track how people respond to coupon offers, in order to more fine-tune a company&amp;#39;s marketing strategy? There are many of these &amp;quot;data analyst&amp;quot; positions available as well, and they are usually in high demand all across the country. There are also all kinds of jobs inbetween.&lt;br&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;Do some research on job sites, such as &lt;a href=&quot;http://jobsearch.monster.com/search/data-science_5&quot;&gt;monster&lt;/a&gt; or &lt;a href=&quot;http://www.indeed.com/jobs?q=data+science&amp;l=&quot;&gt;indeed&lt;/a&gt;, to see what data science jobs are out there. Read the job descriptions and requirements to see what types of positions you&amp;#39;re interested in and/or qualified for.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;After doing some background research on what jobs you might want, there are many diverging paths to take. Everyone&amp;#39;s individual preparation method will be different in several areas:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;What programs you&amp;#39;ll need to learn.&lt;/strong&gt; Big Data jobs: definitely brush up on Hadoop, MapReduce, Pig, Hive, etc. Learn a legitimate programming language, like Python. Depending on the company, they may also want an even newer language, like &lt;a href=&quot;http://julialang.org&quot;&gt;Julia&lt;/a&gt;. Going for an analyst position? Make sure you know your SQL backwards and forwards, as many business databases are MySQL. Depending on the company, you may not even need to learn a programming language: all calculations are expected to be in Excel! This doesn&amp;#39;t mean it&amp;#39;s easier, however; learning how to make Excel do advanced things requires just as much time as Python. Maybe even longer!&lt;br&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;Also be aware of how &amp;quot;stats-forward&amp;quot; your potential jobs may be. If you&amp;#39;re going into Big Data, or a data-science-heavy company, you may need to brush up on your statistics in order to understand and implement Bayesian methods. If you&amp;#39;re going into an analyst position, you might not need to know as much, because Bayesian models may hurt your cause, rather than help (see below).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;What methods and algorithms you&amp;#39;ll need to employ.&lt;/strong&gt; Lots of data science is crunching numbers, but that&amp;#39;s not the only thing available. Some data science mines text, for example to detect plagiarism in student papers. If you find many job listingss where this might be a component, you should learn more about Natural Language Processing. Similarly, some data science focuses on images; perhaps automatically comparing signatures on checks or handwriting in documents to detect fraud. Look into image processing algorithms, which may be useful here.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;How you&amp;#39;ll need to communicate.&lt;/strong&gt; &lt;em&gt;All data science should further the business goals&lt;/em&gt; (pound that notion in). Regardless of where you&amp;#39;re working, or what you&amp;#39;re doing, you will &lt;em&gt;always&lt;/em&gt; have to be justifying your thoughts, approach, and implementation to others, higher up. If you cannot sell them on what you&amp;#39;re doing, do not expect to be able to move forward (see how this is different than hard science?). How you have to defend yourself, and what tools you&amp;#39;ll be &amp;quot;allowed&amp;quot; to use, however, will vary greatly from job to job.&lt;br&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;At a company with a large focus on data science, you may be working with an entire team of data scientists. You may have managers (who themselves are data scientists), who will act as the intermediary between you and the business leaders. You need to sell the managers, who will then take it upon themselves to sell the executives. This is a somewhat easier setup: the people you are directly interfacing with understand data science. You can talk about Bayesian statistics, ensemble methods and specific python modules to bolster your case, and they will be able to speak the same language.&lt;br&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;Going to an analyst position, or a company with a small data science team? You may be speaking directly to executives to sell them on your plan. While more advanced classification schemes, such as Bayes, may provide better results, they may hamper your efforts here, because nobody you&amp;#39;re talking to will understand them! You may be forced to fall back to simple Decision Tree Classifiers, which you can plot, and everyone can understand. Be prepared to &amp;quot;dumb down&amp;quot; your models, or be able to explain them creatively, so that everyone can get on board.&lt;br&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;This is another area where data science (and business in general) is different than science. In science, you are judged by the quality of your work, and only slightly by how you present it. If you have an amazing find, but you stammer a bit in your talk, or your paper is a little disorganized, you still may be lauded in the scientific community. In business, it&amp;#39;s the opposite: it doesn&amp;#39;t matter whether you found an amazing classification model if you can&amp;#39;t explain it. If you stumble through a meeting with executives, your entire project may be killed, even if it would have saved the company millions of dollars. &lt;em&gt;Practice your public speaking!&lt;/em&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;So now that you&amp;#39;ve hammered out your list of things you need to learn, how will you do that? The best option is to look to free online courses, from places like Coursera, or Udacity. Another good option is just search the web for resources on the specific area you want to learn. Hadoop has an &lt;a href=&quot;http://lintool.github.io/Cloud9/&quot;&gt;excellent walkthrough&lt;/a&gt; online, and many of these other advanced tools do as well.&lt;/p&gt;

&lt;p&gt;Not only will you be learning relevant skills for your future job, but you&amp;#39;ll also be proving to a future employer that you &lt;em&gt;can&lt;/em&gt;. I&amp;#39;ve heard from many people in the industry that most of what companies care about are inherent traits, not skills. Sure, being able to check off the list of requirements is good, but they more want to see whether you are a deep quantitative thinker, whether you&amp;#39;re able to carry out independent projects in a timely manner, and whether you&amp;#39;re able to efficiently learn new skills that may be necessary for the job. Show them that you can.&lt;/p&gt;

&lt;p&gt;Lastly, put those skills to use and practice! &lt;a href=&quot;http://www.kaggle.com&quot;&gt;Kaggle.com&lt;/a&gt; has many excellent challenges that give you chances to work on real datasets, and test your algorthims&amp;#39; accuracy. They range in difficulty and approach, providing challenges for any realm of data science you wish to enter. Go check them out!&lt;/p&gt;
</description>
        <pubDate>Tue, 29 Jul 2014 00:00:00 -0700</pubDate>
        <link>http://localhost:4000/blog/transition-to-data-science/</link>
        <guid isPermaLink="true">http://localhost:4000/blog/transition-to-data-science/</guid>
        
        <category>Data Science</category>
        
        
        <category>blog</category>
        
      </item>
    
  </channel>
</rss>
